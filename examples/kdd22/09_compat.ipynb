{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KDD 2022 Hands-on Tutorial on \"Gradual AutoML using Lale\"\n",
    "\n",
    "# 9. Compatibility with scikit-learn\n",
    "\n",
    "Lale, as a wrapper around scikit-learn, tries to simplify compatibility with scikit-learn.\n",
    "For example, in many cases, a scikit-learn operator can be passed to Lale,\n",
    "and a Lale operator can be used with scikit-learn.\n",
    "\n",
    "This notebook presents some more information about converting scikit-learn code to lale,\n",
    "and some important compatibility features.\n",
    "\n",
    "The [New Operators](08_newops.ipynb) notebook contains information on how to create lale wrappers for custom\n",
    "operators.\n",
    "\n",
    "This notebook has the following sections:\n",
    "\n",
    "- [9.1 Going from scikit-learn to Lale](#9.1-Going-from-scikit-learn-to-Lale)\n",
    "- [9.2 Going from Lale to scikit-learn](#9.2-Going-from-Lale-to-scikit-learn)\n",
    "- [9.3 scikit-learn Conventions and Lale](#9.3-scikit-learn-Conventions-and-Lale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 Going from scikit-learn to Lale\n",
    "\n",
    "Given existing pipelines that uses scikit-learn, there are a number of ways that they can be converted into Lale pipelines.\n",
    "As an example, assume the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_sklearn():\n",
    "    from sklearn.pipeline import make_pipeline\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    return make_pipeline(MinMaxScaler(), PCA(), RandomForestClassifier())\n",
    "\n",
    "import sklearn.pipeline\n",
    "assert isinstance(example_sklearn(), sklearn.pipeline.Pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1.1 Changing Imports\n",
    "\n",
    "Assuming that Lale provides wrappers for the operators being used, \n",
    "it is generally straightforward to change the `import` declarations\n",
    "to use the Lale wrappers instead of the underlying impl.\n",
    "For our example, this would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_imports():\n",
    "    from lale.operators import make_pipeline\n",
    "    from lale.lib.sklearn import MinMaxScaler\n",
    "    from lale.lib.sklearn import PCA\n",
    "    from lale.lib.sklearn import RandomForestClassifier\n",
    "    return make_pipeline(MinMaxScaler(), PCA(), RandomForestClassifier())\n",
    "\n",
    "import lale.operators\n",
    "assert isinstance(example_imports(), lale.operators.TrainablePipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can also change the code to be more idiomatic by using Lale combinators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_idiomatic():\n",
    "    from lale.lib.sklearn import MinMaxScaler\n",
    "    from lale.lib.sklearn import PCA\n",
    "    from lale.lib.sklearn import RandomForestClassifier\n",
    "    return MinMaxScaler() >> PCA() >> RandomForestClassifier()\n",
    "\n",
    "assert isinstance(example_idiomatic(), lale.operators.TrainablePipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1.2 `wrap_imported_operators`\n",
    "Alternatively, instead of changing the imports, you can call \n",
    "`lale.wrap_imported_operators` to change the imports for you,\n",
    "as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from lale import wrap_imported_operators\n",
    "wrap_imported_operators()\n",
    "\n",
    "example_wrapped = make_pipeline(MinMaxScaler(), PCA(), RandomForestClassifier())\n",
    "assert isinstance(example_wrapped.steps[0][1], lale.operators.TrainableIndividualOp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `wrap_imported_operators` function modifies the symbol table\n",
    "so that the imported names actually refer to their Lale wrappers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1.3 `import_from_sklearn_pipeline`\n",
    "\n",
    "The previous two options work well for migrating source code.\n",
    "However, there are some situations where you are provided, at runtime, with\n",
    "an existing scikit-learn pipeline object, rather than its source code.\n",
    "This object can be converted into a Lale pipeline (and its operators replaced with the appropriate Lale wrappers, when possible) by calling `import_from_sklearn_pipeline` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: cluster:(root) Pages: 1 -->\n",
       "<svg width=\"287pt\" height=\"65pt\"\n",
       " viewBox=\"0.00 0.00 286.74 64.57\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 60.57)\">\n",
       "<title>cluster:(root)</title>\n",
       "<g id=\"a_graph0\"><a xlink:title=\"(root) = ...\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-60.57 282.74,-60.57 282.74,4 -4,4\"/>\n",
       "</a>\n",
       "</g>\n",
       "<!-- min_max_scaler -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>min_max_scaler</title>\n",
       "<g id=\"a_node1\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.sklearn.min_max_scaler.html\" target=\"_blank\" rel=\"noopener noreferrer\" xlink:title=\"min_max_scaler = MinMaxScaler()\">\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"31.82\" cy=\"-28.28\" rx=\"31.64\" ry=\"28.07\"/>\n",
       "<text text-anchor=\"middle\" x=\"31.82\" y=\"-37.48\" font-family=\"Times,serif\" font-size=\"11.00\">Min&#45;</text>\n",
       "<text text-anchor=\"middle\" x=\"31.82\" y=\"-25.48\" font-family=\"Times,serif\" font-size=\"11.00\">Max&#45;</text>\n",
       "<text text-anchor=\"middle\" x=\"31.82\" y=\"-13.48\" font-family=\"Times,serif\" font-size=\"11.00\">Scaler</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- pca -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>pca</title>\n",
       "<g id=\"a_node2\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.sklearn.pca.html\" target=\"_blank\" rel=\"noopener noreferrer\" xlink:title=\"pca = PCA()\">\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"126.64\" cy=\"-28.28\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"126.64\" y=\"-25.48\" font-family=\"Times,serif\" font-size=\"11.00\">PCA</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- min_max_scaler&#45;&gt;pca -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>min_max_scaler&#45;&gt;pca</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M63.73,-28.28C71.98,-28.28 80.96,-28.28 89.47,-28.28\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"89.52,-31.78 99.52,-28.28 89.52,-24.78 89.52,-31.78\"/>\n",
       "</g>\n",
       "<!-- random_forest_classifier -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>random_forest_classifier</title>\n",
       "<g id=\"a_node3\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.sklearn.random_forest_classifier.html\" target=\"_blank\" rel=\"noopener noreferrer\" xlink:title=\"random_forest_classifier = RandomForestClassifier()\">\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"234.19\" cy=\"-28.28\" rx=\"44.6\" ry=\"28.07\"/>\n",
       "<text text-anchor=\"middle\" x=\"234.19\" y=\"-37.48\" font-family=\"Times,serif\" font-size=\"11.00\">Random&#45;</text>\n",
       "<text text-anchor=\"middle\" x=\"234.19\" y=\"-25.48\" font-family=\"Times,serif\" font-size=\"11.00\">Forest&#45;</text>\n",
       "<text text-anchor=\"middle\" x=\"234.19\" y=\"-13.48\" font-family=\"Times,serif\" font-size=\"11.00\">Classifier</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- pca&#45;&gt;random_forest_classifier -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>pca&#45;&gt;random_forest_classifier</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M153.73,-28.28C161.54,-28.28 170.4,-28.28 179.31,-28.28\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"179.32,-31.78 189.32,-28.28 179.32,-24.78 179.32,-31.78\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f8795034590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lale.helpers import import_from_sklearn_pipeline\n",
    "\n",
    "sk_pipe = example_sklearn()\n",
    "assert isinstance(sk_pipe, sklearn.pipeline.Pipeline)\n",
    "assert not isinstance(sk_pipe, lale.operators.TrainablePipeline)\n",
    "imported_pipe = import_from_sklearn_pipeline(sk_pipe)\n",
    "assert isinstance(imported_pipe, lale.operators.TrainablePipeline)\n",
    "imported_pipe.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 Going from Lale to scikit-learn\n",
    "\n",
    "Sometimes there is a need to get the underlying operators out.\n",
    "\n",
    "### 9.2.1 Individual Operators\n",
    "\n",
    "To get the operator underlying a Lale wrapper, use its `impl` property.\n",
    "For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lale_pipeline = example_idiomatic()\n",
    "lale_op = lale_pipeline.steps[0][1]\n",
    "assert isinstance(lale_op, lale.operators.TrainableIndividualOp)\n",
    "op_impl = lale_op.impl\n",
    "import sklearn.base\n",
    "assert isinstance(op_impl, sklearn.base.BaseEstimator)\n",
    "assert not isinstance(op_impl, lale.operators.TrainableIndividualOp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2.2 A Pipeline\n",
    "\n",
    "The `export_to_sklearn_pipeline` method will try to convert a pipeline into a scikit-learn pipeline, recursively converting its constituent operators into their unwrapped, base implementations.\n",
    "Note that this is not always possible, as Lale pipelines are strictly more expressive than scikit-learn pipelines.\n",
    "As an example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hirzel/py_venv_lale_tutorial/lib/python3.7/site-packages/sklearn/utils/deprecation.py:103: FutureWarning: Attribute `n_features_` was deprecated in version 1.0 and will be removed in 1.2. Use `n_features_in_` instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "exported_pipeline = lale_pipeline.export_to_sklearn_pipeline()\n",
    "assert isinstance(exported_pipeline, sklearn.pipeline.Pipeline)\n",
    "assert not isinstance(exported_pipeline, lale.operators.TrainablePipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3 scikit-learn Conventions and Lale\n",
    "\n",
    "When possible, Lale supports various scikit-learn conventions.  \n",
    "In particular, it supports cloning, parameter getting/setting, property forwarding, and operator type checking.\n",
    "To present some examples, we first load a dataset and use it to train our Lale pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lale.datasets.openml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "(train_X, train_y), (test_X, test_y) = lale.datasets.openml.fetch(\n",
    "    \"credit-g\", \"classification\", preprocess=True\n",
    ")\n",
    "trained_lale_pipeline = lale_pipeline.fit(np.array(train_X), np.array(train_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3.1 `clone`-ing\n",
    "In scikit-learn, operators are cloned using the [sklearn.base.clone](https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html) method.  \n",
    "Lale is carefully designed so that calling this `clone` method on a lale operator will work, behaving as it does for scikit-learn operators.  Note that as per scikit-learn conventions, calling `clone` on a `TrainedOperator` will return a `TrainableOperator`, since, by design, cloning does not preserve learned coefficients.\n",
    "As an example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "assert isinstance(clone(lale_pipeline), lale.operators.TrainablePipeline)\n",
    "assert isinstance(clone(trained_lale_pipeline), lale.operators.TrainablePipeline)\n",
    "assert not isinstance(clone(trained_lale_pipeline), lale.operators.TrainedPipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3.2 `get/set/with_params`\n",
    "Like scikit-learn operators, Lale operators provide a `get_params` method to retrieve the hyper-parameters set for an operator/pipeline, and `set_params` to set those parameters.\n",
    "Lale also provides `with_params`, a functional variant of `set_params` that creates a new copy of the operator with the modified hyperparameters instead of mutating the given operator.\n",
    "When any of these methods are used on a pipeline, the scikit-learn convention of prepending `operatorname__` to the hyerparameter name is used.\n",
    "Additional encodings are used for other pipeline features that scikit-learn does not support, such as choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'steps': [MinMaxScaler(), PCA(), RandomForestClassifier()],\n",
       " 'MinMaxScaler__clip': False,\n",
       " 'MinMaxScaler__copy': True,\n",
       " 'MinMaxScaler__feature_range': (0, 1),\n",
       " 'PCA__copy': True,\n",
       " 'PCA__iterated_power': 'auto',\n",
       " 'PCA__n_components': None,\n",
       " 'PCA__random_state': None,\n",
       " 'PCA__svd_solver': 'auto',\n",
       " 'PCA__tol': 0.0,\n",
       " 'PCA__whiten': False,\n",
       " 'RandomForestClassifier__bootstrap': True,\n",
       " 'RandomForestClassifier__ccp_alpha': 0.0,\n",
       " 'RandomForestClassifier__class_weight': None,\n",
       " 'RandomForestClassifier__criterion': 'gini',\n",
       " 'RandomForestClassifier__max_depth': None,\n",
       " 'RandomForestClassifier__max_features': 'auto',\n",
       " 'RandomForestClassifier__max_leaf_nodes': None,\n",
       " 'RandomForestClassifier__max_samples': None,\n",
       " 'RandomForestClassifier__min_impurity_decrease': 0.0,\n",
       " 'RandomForestClassifier__min_samples_leaf': 1,\n",
       " 'RandomForestClassifier__min_samples_split': 2,\n",
       " 'RandomForestClassifier__min_weight_fraction_leaf': 0.0,\n",
       " 'RandomForestClassifier__n_estimators': 100,\n",
       " 'RandomForestClassifier__n_jobs': None,\n",
       " 'RandomForestClassifier__oob_score': False,\n",
       " 'RandomForestClassifier__random_state': None,\n",
       " 'RandomForestClassifier__verbose': 0,\n",
       " 'RandomForestClassifier__warm_start': False}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lale_pipeline.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  9.3.3 Attribute Forwarding\n",
    "\n",
    "Many operator implementations provide additional properties or methods that provide additional information, especially after the operator has been trained.\n",
    "If needed, these can be accessed using the operator `.impl` property, as mentioned above.\n",
    "However, this is generally not needed, as Lale supports transparent forwarding of properties/fields/methods.\n",
    "As long as there is no name conflict (such as a property called `get_params`), unknown attributes are transparently forwarded to the underlying implementation for resolution.  As mentioned in the [New Operators](08_newops.ipynb) notebook, this can be restricted by the operator for increased control.\n",
    "In addition to convenience, this enables Lale operators to replace unwrapped scikit-learn operators with minimal changes needed to the code.\n",
    "As an example, the MinMaxScalar implementation sets the `n_features_in_` property after `fit` is called:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_minmax = trained_lale_pipeline.steps[0][1]\n",
    "assert trained_minmax.n_features_in_ == trained_minmax.impl.n_features_in_ == 61"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  9.3.4 `isinstance` Checking\n",
    "\n",
    "It is sometimes important to check the type of an operator.  For example, code may wish to have a special case for\n",
    "`MinMaxScaler`, and would like to check if an operator is that type.\n",
    "In Lale, this would appear to be challenging, due to our use of wrapper classes.  Nonetheless, due to judicious use of Python's features, it is possible to use a simple `isinstance` check as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lale.lib.sklearn import MinMaxScaler\n",
    "\n",
    "assert isinstance(trained_minmax, lale.operators.Operator)\n",
    "assert isinstance(trained_minmax, MinMaxScaler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
