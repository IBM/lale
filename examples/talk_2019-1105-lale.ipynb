{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lale: Library for Semi-Automated Data Science\n",
    "\n",
    "Martin Hirzel, Kiran Kate, Avi Shinnar, Guillaume Baudart, and Pari Ram\n",
    "\n",
    "5 November 2019\n",
    "\n",
    "Examples, documentation, code: https://github.com/ibm/lale\n",
    "\n",
    "<img src=\"../docs/img/lale_logo.jpg\" alt=\"logo\" width=\"140px\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is the basis for a\n",
    "[talk](https://pydata.org/nyc2019/schedule/presentation/29/type-driven-automated-learning-with-lale/)\n",
    "about [Lale](https://github.com/ibm/lale).  Lale is an open-source\n",
    "Python library for semi-automated data science. Lale is compatible\n",
    "with scikit-learn, adding a simple interface to existing\n",
    "machine-learning automation tools. Lale lets you search over possible\n",
    "pipelines in just a few lines of code while remaining in control of\n",
    "your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Proposition\n",
    "\n",
    "When writing machine-learning pipelines, you have a lot of decisions\n",
    "to make, such as picking transformers, estimators, and\n",
    "hyperparameters. Since some of these decisions are tricky, you will\n",
    "likely find yourself searching over many possible pipelines.\n",
    "Machine-learning automation tools help with this search.\n",
    "Unfortunately, each of these tools has its own API, and the search\n",
    "spaces are not necessarily consistent nor even correct. We have\n",
    "discovered that types (such as enum, float, or dictionary) can both\n",
    "check the correctness of, and help automatically search over,\n",
    "hyperparameters and pipeline configurations.\n",
    "\n",
    "To address this issue, we have open-sourced Lale, an open-source\n",
    "Python library for semi-automated data science. Lale is compatible\n",
    "with scikit-learn, adding a simple interface to existing\n",
    "machine-learning automation tools. Lale lets you search over possible\n",
    "pipelines in just a few lines of code while remaining in control of\n",
    "your work. In other words, Lale is designed to augment, but not\n",
    "replace, the data scientist.\n",
    "\n",
    "The **target user** of Lale is the working data scientist.\n",
    "The **scope** of Lale includes machine learning (both deep learning\n",
    "and non-DL) and data preparation. The **value** of Lale encompasses:\n",
    "\n",
    "<img src=\"img/2019-1105-three-values.png\" style=\"width:350px\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical + Continuous Dataset\n",
    "\n",
    "We will demonstrate automated machine learning (AutoML), we first need\n",
    "a dataset. We will use a tabular dataset that has two kinds of\n",
    "features: categorical features (columns that can contain one of a\n",
    "small set of strings) and continuous features (numerical columns).  In\n",
    "particular, we use the `credit-g` dataset from OpenML. After fetching\n",
    "the data, we display a few rows to get a better understanding of its\n",
    "labels and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>checking_status</th>\n",
       "      <th>duration</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>savings_status</th>\n",
       "      <th>employment</th>\n",
       "      <th>installment_commitment</th>\n",
       "      <th>personal_status</th>\n",
       "      <th>...</th>\n",
       "      <th>residence_since</th>\n",
       "      <th>property_magnitude</th>\n",
       "      <th>age</th>\n",
       "      <th>other_payment_plans</th>\n",
       "      <th>housing</th>\n",
       "      <th>existing_credits</th>\n",
       "      <th>job</th>\n",
       "      <th>num_dependents</th>\n",
       "      <th>own_telephone</th>\n",
       "      <th>foreign_worker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>no credits/all paid</td>\n",
       "      <td>new car</td>\n",
       "      <td>1082.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>1&lt;=X&lt;4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>male single</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>car</td>\n",
       "      <td>48.0</td>\n",
       "      <td>bank</td>\n",
       "      <td>own</td>\n",
       "      <td>2.0</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1.0</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0</td>\n",
       "      <td>0&lt;=X&lt;200</td>\n",
       "      <td>27.0</td>\n",
       "      <td>existing paid</td>\n",
       "      <td>business</td>\n",
       "      <td>3915.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>1&lt;=X&lt;4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>male single</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>car</td>\n",
       "      <td>36.0</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1.0</td>\n",
       "      <td>skilled</td>\n",
       "      <td>2.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>1</td>\n",
       "      <td>no checking</td>\n",
       "      <td>9.0</td>\n",
       "      <td>existing paid</td>\n",
       "      <td>education</td>\n",
       "      <td>3832.0</td>\n",
       "      <td>no known savings</td>\n",
       "      <td>&gt;=7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>male single</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>real estate</td>\n",
       "      <td>64.0</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1.0</td>\n",
       "      <td>unskilled resident</td>\n",
       "      <td>1.0</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>0&lt;=X&lt;200</td>\n",
       "      <td>18.0</td>\n",
       "      <td>critical/other existing credit</td>\n",
       "      <td>furniture/equipment</td>\n",
       "      <td>1928.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>&lt;1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>male single</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>real estate</td>\n",
       "      <td>31.0</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>2.0</td>\n",
       "      <td>unskilled resident</td>\n",
       "      <td>1.0</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>1</td>\n",
       "      <td>0&lt;=X&lt;200</td>\n",
       "      <td>36.0</td>\n",
       "      <td>delayed previously</td>\n",
       "      <td>business</td>\n",
       "      <td>9857.0</td>\n",
       "      <td>100&lt;=X&lt;500</td>\n",
       "      <td>4&lt;=X&lt;7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>male single</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>life insurance</td>\n",
       "      <td>31.0</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>2.0</td>\n",
       "      <td>unskilled resident</td>\n",
       "      <td>2.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y checking_status  duration                  credit_history  \\\n",
       "835  0              <0      12.0             no credits/all paid   \n",
       "192  0        0<=X<200      27.0                   existing paid   \n",
       "629  1     no checking       9.0                   existing paid   \n",
       "559  0        0<=X<200      18.0  critical/other existing credit   \n",
       "684  1        0<=X<200      36.0              delayed previously   \n",
       "\n",
       "                 purpose  credit_amount    savings_status employment  \\\n",
       "835              new car         1082.0              <100     1<=X<4   \n",
       "192             business         3915.0              <100     1<=X<4   \n",
       "629            education         3832.0  no known savings        >=7   \n",
       "559  furniture/equipment         1928.0              <100         <1   \n",
       "684             business         9857.0        100<=X<500     4<=X<7   \n",
       "\n",
       "     installment_commitment personal_status  ... residence_since  \\\n",
       "835                     4.0     male single  ...             4.0   \n",
       "192                     4.0     male single  ...             2.0   \n",
       "629                     1.0     male single  ...             4.0   \n",
       "559                     2.0     male single  ...             2.0   \n",
       "684                     1.0     male single  ...             3.0   \n",
       "\n",
       "     property_magnitude   age  other_payment_plans housing existing_credits  \\\n",
       "835                 car  48.0                 bank     own              2.0   \n",
       "192                 car  36.0                 none     own              1.0   \n",
       "629         real estate  64.0                 none     own              1.0   \n",
       "559         real estate  31.0                 none     own              2.0   \n",
       "684      life insurance  31.0                 none     own              2.0   \n",
       "\n",
       "                    job num_dependents  own_telephone foreign_worker  \n",
       "835             skilled            1.0           none            yes  \n",
       "192             skilled            2.0            yes            yes  \n",
       "629  unskilled resident            1.0           none            yes  \n",
       "559  unskilled resident            1.0           none            yes  \n",
       "684  unskilled resident            2.0            yes            yes  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lale.datasets.openml\n",
    "import pandas as pd\n",
    "(train_X, train_y), (test_X, test_y) = lale.datasets.openml.fetch(\n",
    "    'credit-g', 'classification', preprocess=False)\n",
    "# print last five rows of labels in train_y and features in train_X\n",
    "pd.concat([pd.DataFrame({'y': train_y}, index=train_X.index).tail(5),\n",
    "           train_X.tail(5)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels `y` are either 0 or 1, which means that this is a binary\n",
    "classification task. The remaining 20 columns are features. Some of the\n",
    "features are categorical, such as `checking_status` or\n",
    "`credit_history`. Other features are continuous, such as `duration` or\n",
    "`credit_amount`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Pipeline\n",
    "\n",
    "Lale is designed to support both manual and automated data science,\n",
    "with a consistent API that works for both of these cases as well as\n",
    "for the spectrum of semi-automated cases in between. A\n",
    "machine-learning *pipeline* is a computational graph, where each\n",
    "node is an *operator* (which transforms data or makes predictions)\n",
    "and each edge is an intermediary *dataset* (outputs from previous\n",
    "operators are piped as inputs to the next operators). We first import\n",
    "some operators from scikit-learn and auto-wrap them for use with Lale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer as Norm\n",
    "from sklearn.preprocessing import OneHotEncoder as OneHot\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "import lale.helpers\n",
    "lale.helpers.wrap_imported_operators()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell imports a couple of utility operators from Lale's\n",
    "standard library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lale.lib.lale import Project\n",
    "from lale.lib.lale import ConcatFeatures as Concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the operators we need, we arrange them into a\n",
    "pipeline. The `Project` operator works like the corresponding\n",
    "relational algebra primitive, picking a subset of the columns of the\n",
    "dataset. An expression of the form `op1 >> op2` *pipes* the output\n",
    "from `op1` into `op2`. An expression of the form `op1 & op2` causes\n",
    "both op1 *and* op2 to execute on the same data. Overall, this pipeline\n",
    "preprocesses numbers with a normalizer and strings with a one-hot\n",
    "encoder, then concatenates the corresponding columns and pipes the\n",
    "result into an `LR` classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"332pt\" height=\"102pt\"\n",
       " viewBox=\"0.00 0.00 332.00 101.80\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 97.799)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-97.799 328,-97.799 328,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<g id=\"a_node1\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.lale.project.html\" xlink:title=\"Project(columns={&#39;type&#39;: &#39;number&#39;})\">\n",
       "<ellipse fill=\"#b0e2ff\" stroke=\"black\" cx=\"27\" cy=\"-75.799\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-72.999\" font-family=\"Times,serif\" font-size=\"11.00\">Project</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\n",
       "<g id=\"a_node2\"><a xlink:href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html\" xlink:title=\"Norm\">\n",
       "<ellipse fill=\"#b0e2ff\" stroke=\"black\" cx=\"117\" cy=\"-75.799\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"117\" y=\"-72.999\" font-family=\"Times,serif\" font-size=\"11.00\">Norm</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54.4029,-75.799C62.3932,-75.799 71.3106,-75.799 79.8241,-75.799\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"79.919,-79.2991 89.919,-75.799 79.919,-72.2991 79.919,-79.2991\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\n",
       "<g id=\"a_node5\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.lale.concat_features.html\" xlink:title=\"Concat\">\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"207\" cy=\"-47.799\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"207\" y=\"-44.999\" font-family=\"Times,serif\" font-size=\"11.00\">Concat</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;4 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>1&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M141.582,-68.2955C151.151,-65.2511 162.374,-61.68 172.748,-58.3792\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"173.884,-61.6905 182.353,-55.3232 171.762,-55.0201 173.884,-61.6905\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\n",
       "<g id=\"a_node3\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.lale.project.html\" xlink:title=\"Project(columns={&#39;type&#39;: &#39;string&#39;})\">\n",
       "<ellipse fill=\"#b0e2ff\" stroke=\"black\" cx=\"27\" cy=\"-19.799\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-16.999\" font-family=\"Times,serif\" font-size=\"11.00\">Project</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\n",
       "<g id=\"a_node4\"><a xlink:href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\" xlink:title=\"OneHot\">\n",
       "<ellipse fill=\"#b0e2ff\" stroke=\"black\" cx=\"117\" cy=\"-19.799\" rx=\"27\" ry=\"19.6\"/>\n",
       "<text text-anchor=\"middle\" x=\"117\" y=\"-22.999\" font-family=\"Times,serif\" font-size=\"11.00\">One&#45;</text>\n",
       "<text text-anchor=\"middle\" x=\"117\" y=\"-10.999\" font-family=\"Times,serif\" font-size=\"11.00\">Hot</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54.4029,-19.799C62.3932,-19.799 71.3106,-19.799 79.8241,-19.799\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"79.919,-23.2991 89.919,-19.799 79.919,-16.2991 79.919,-23.2991\"/>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M142.046,-27.4501C151.435,-30.4375 162.362,-33.9143 172.5,-37.1398\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"171.697,-40.5572 182.287,-40.2541 173.819,-33.8867 171.697,-40.5572\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\n",
       "<g id=\"a_node6\"><a xlink:href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" xlink:title=\"LR(penalty=&#39;l1&#39;, C=0.001)\">\n",
       "<ellipse fill=\"#b0e2ff\" stroke=\"black\" cx=\"297\" cy=\"-47.799\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"297\" y=\"-44.999\" font-family=\"Times,serif\" font-size=\"11.00\">LR</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M234.403,-47.799C242.393,-47.799 251.311,-47.799 259.824,-47.799\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"259.919,-51.2991 269.919,-47.799 259.919,-44.2991 259.919,-51.2991\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fb0aa391a90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_trainable = (\n",
    "       (  Project(columns={'type': 'number'}) >> Norm()\n",
    "        & Project(columns={'type': 'string'}) >> OneHot())\n",
    "    >> Concat\n",
    "    >> LR(LR.penalty.l1, C=0.001))\n",
    "lale.helpers.to_graphviz(manual_trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we have manually chosen all operators and configured\n",
    "their hyperparameters. For the `LR` operator, we configured the\n",
    "penalty hyperparameter with `l1` and the regularization constant `C`\n",
    "with `0.001`. You can explore these hyperparameters by hovering over\n",
    "the visualization above and observing the tooltips that pop up.\n",
    "Furthermore, each node in the visualization is a hyperlink that takes\n",
    "you to the documentation of the corresponding operator.  Calling `fit`\n",
    "on the trainable pipeline returns a trained pipeline, and calling\n",
    "`predict` on the trained pipeline returns predictions. We can use\n",
    "off-the-shelf scikit-learn metrics to evaluate the result. In this\n",
    "case, the accuracy is poor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 29.1%\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "manual_trained = manual_trainable.fit(train_X, train_y)\n",
    "manual_y = manual_trained.predict(test_X)\n",
    "print(f'accuracy {sklearn.metrics.accuracy_score(test_y, manual_y):.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Combinators\n",
    "\n",
    "As the previous example demonstrates, Lale operators combinators `>>`\n",
    "and `&` for arranging operators into a pipeline. These combinators are\n",
    "actually syntactic sugar for functions `make_pipeline` and\n",
    "`make_union`, which were inspired by the corresponding functions in\n",
    "scikit-learn. To support Auto-ML, Lale supports a third combinator `|`\n",
    "that specifies an algorithmic choice. Scikit-learn does not have a\n",
    "corresponding function. Various Auto-ML tools support algorithmic\n",
    "choice in some form or other, using their own tool-specific syntax.\n",
    "Lale's `|` combinator is syntactic sugar for Lale's `make_choice`\n",
    "function.\n",
    "\n",
    "| Lale feature            | Name | Description  | Scikit-learn feature                 |\n",
    "| ----------------------- | ---- | ------------ | ------------------------------------ |\n",
    "| >> or `make_pipeline`   | pipe | feed to next | `make_pipeline`                      |\n",
    "| & or `make_union`       | and  | run both     | `make_union` or `ColumnTransformer`  |\n",
    "| &#x7c; or `make_choice` | or   | choose one   | N/A (specific to given Auto-ML tool) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated Pipeline\n",
    "\n",
    "Next, we will use automation to search for a better pipeline for the\n",
    "same dataset as before. Specifically, we will perform combined\n",
    "hyperparameter optimization and algorithm selection (CASH). To do\n",
    "this, we first import a couple more operators to serve as choices in\n",
    "the algorithm selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier as XGBoost\n",
    "from sklearn.svm import LinearSVC\n",
    "lale.helpers.wrap_imported_operators()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we arrange the pipeline that specifies the search space for\n",
    "CASH. As promised, the look-and-feel for the automated case resembles\n",
    "that for the manual case from earlier. The main difference is the use\n",
    "of the `|` combinator to provide algorithmic choice (`LR | XGBoost |\n",
    "LinearSVC`). However, there is another difference: several of the\n",
    "operators are not configured with hyperparameters. For instance, this\n",
    "pipeline writes `LR` instead of `LR(LR.penalty.l1, C=0.001)`.\n",
    "Omitting the arguments means that as the data scientist, we do not\n",
    "bind the hyperparameters by hand in this pipeline. Instead, we leave\n",
    "these bindings free for CASH to search over. Similarly, the code does\n",
    "writes `Norm` instead of `Norm()` and `OneHot` instead of `OneHot`.\n",
    "This illustrates that automated hyperparameter tuning can be used not\n",
    "only on the final classifier but also inside of nested preprocessing\n",
    "sub-pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"425pt\" height=\"102pt\"\n",
       " viewBox=\"0.00 0.00 425.35 101.80\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 97.799)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-97.799 421.353,-97.799 421.353,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<g id=\"a_node1\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.lale.project.html\" xlink:title=\"Project(columns={&#39;type&#39;: &#39;number&#39;})\">\n",
       "<ellipse fill=\"#b0e2ff\" stroke=\"black\" cx=\"27\" cy=\"-75.799\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-72.999\" font-family=\"Times,serif\" font-size=\"11.00\">Project</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\n",
       "<g id=\"a_node2\"><a xlink:href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html\" xlink:title=\"Norm\">\n",
       "<ellipse fill=\"#7ec0ee\" stroke=\"black\" cx=\"117\" cy=\"-75.799\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"117\" y=\"-72.999\" font-family=\"Times,serif\" font-size=\"11.00\">Norm</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54.4029,-75.799C62.3932,-75.799 71.3106,-75.799 79.8241,-75.799\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"79.919,-79.2991 89.919,-75.799 79.919,-72.2991 79.919,-79.2991\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\n",
       "<g id=\"a_node5\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.lale.concat_features.html\" xlink:title=\"Concat\">\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"207\" cy=\"-47.799\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"207\" y=\"-44.999\" font-family=\"Times,serif\" font-size=\"11.00\">Concat</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;4 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>1&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M141.582,-68.2955C151.151,-65.2511 162.374,-61.68 172.748,-58.3792\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"173.884,-61.6905 182.353,-55.3232 171.762,-55.0201 173.884,-61.6905\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\n",
       "<g id=\"a_node3\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.lale.project.html\" xlink:title=\"Project(columns={&#39;type&#39;: &#39;string&#39;})\">\n",
       "<ellipse fill=\"#b0e2ff\" stroke=\"black\" cx=\"27\" cy=\"-19.799\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-16.999\" font-family=\"Times,serif\" font-size=\"11.00\">Project</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\n",
       "<g id=\"a_node4\"><a xlink:href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\" xlink:title=\"OneHot\">\n",
       "<ellipse fill=\"#7ec0ee\" stroke=\"black\" cx=\"117\" cy=\"-19.799\" rx=\"27\" ry=\"19.6\"/>\n",
       "<text text-anchor=\"middle\" x=\"117\" y=\"-22.999\" font-family=\"Times,serif\" font-size=\"11.00\">One&#45;</text>\n",
       "<text text-anchor=\"middle\" x=\"117\" y=\"-10.999\" font-family=\"Times,serif\" font-size=\"11.00\">Hot</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54.4029,-19.799C62.3932,-19.799 71.3106,-19.799 79.8241,-19.799\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"79.919,-23.2991 89.919,-19.799 79.919,-16.2991 79.919,-23.2991\"/>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M142.046,-27.4501C151.435,-30.4375 162.362,-33.9143 172.5,-37.1398\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"171.697,-40.5572 182.287,-40.2541 173.819,-33.8867 171.697,-40.5572\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\n",
       "<g id=\"a_node6\"><a xlink:title=\"LR | XGBoost | LinearSVC\">\n",
       "<ellipse fill=\"#7ec0ee\" stroke=\"black\" cx=\"343.677\" cy=\"-47.799\" rx=\"73.8537\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"343.677\" y=\"-44.999\" font-family=\"Times,serif\" font-size=\"11.00\">LR | XGBoost | LinearSVC</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M234.287,-47.799C241.876,-47.799 250.59,-47.799 259.709,-47.799\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"259.729,-51.2991 269.729,-47.799 259.729,-44.2991 259.729,-51.2991\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fb096c2a160>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_planned = (\n",
    "       (  Project(columns={'type': 'number'}) >> Norm\n",
    "        & Project(columns={'type': 'string'}) >> OneHot)\n",
    "    >> Concat\n",
    "    >> (LR | XGBoost | LinearSVC))\n",
    "lale.helpers.to_graphviz(auto_planned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The colors in the visualization indicate the particular mix of manual\n",
    "vs. automated bindings and will be explained in more detail below.\n",
    "For now, we look at how to actually invoke an AutoML tool from Lale.\n",
    "Lale provides bindings for multiple such tools; here we use the\n",
    "popular hyperopt open-source library. Specifically,\n",
    "`HyperoptClassifier` takes the `auto_planned` pipeline from above as\n",
    "an argument, along with optional specifications for the number of\n",
    "cross-validation folds and trials to run. Calling `fit` yields a\n",
    "trained pipeline. The code that uses that trained pipeline for\n",
    "prediction and evaluation is the same as in the manual use case we saw\n",
    "before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:36<00:00,  3.54s/it, best loss: -0.7373278347213325]\n",
      "accuracy 75.2%\n"
     ]
    }
   ],
   "source": [
    "from lale.lib.lale.hyperopt_classifier import HyperoptClassifier\n",
    "auto_optimizer = HyperoptClassifier(auto_planned, cv=3, max_evals=10)\n",
    "auto_trained = auto_optimizer.fit(train_X, train_y)\n",
    "auto_y = auto_trained.predict(test_X)\n",
    "print(f'accuracy {sklearn.metrics.accuracy_score(test_y, auto_y):.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictive performance is better, and in fact, it is in the same\n",
    "ball-park as the state-of-the-art performance reported for this\n",
    "dataset in OpenML. Since we left various choices to automation, at\n",
    "this point, we probably want to inspect what the automation decided\n",
    "for us. One way to do that is by visualizing the pipeline as before.\n",
    "This reveals that hyperopt chose `XGBoost` instead of the scikit-learn\n",
    "classifiers. Also, by hovering over the nodes in the visualization, we\n",
    "can explore how hyperopt configured the hyperparameters. Note that all\n",
    "nodes are visualized in white to indicate they are fully trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"332pt\" height=\"102pt\"\n",
       " viewBox=\"0.00 0.00 332.00 101.80\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 97.799)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-97.799 328,-97.799 328,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<g id=\"a_node1\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.lale.project.html\" xlink:title=\"Project(columns={&#39;type&#39;: &#39;number&#39;})\">\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"27\" cy=\"-75.799\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-72.999\" font-family=\"Times,serif\" font-size=\"11.00\">Project</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\n",
       "<g id=\"a_node2\"><a xlink:href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html\" xlink:title=\"Norm\">\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"117\" cy=\"-75.799\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"117\" y=\"-72.999\" font-family=\"Times,serif\" font-size=\"11.00\">Norm</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54.4029,-75.799C62.3932,-75.799 71.3106,-75.799 79.8241,-75.799\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"79.919,-79.2991 89.919,-75.799 79.919,-72.2991 79.919,-79.2991\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\n",
       "<g id=\"a_node5\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.lale.concat_features.html\" xlink:title=\"Concat\">\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"207\" cy=\"-47.799\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"207\" y=\"-44.999\" font-family=\"Times,serif\" font-size=\"11.00\">Concat</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;4 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>1&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M141.582,-68.2955C151.151,-65.2511 162.374,-61.68 172.748,-58.3792\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"173.884,-61.6905 182.353,-55.3232 171.762,-55.0201 173.884,-61.6905\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\n",
       "<g id=\"a_node3\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.lale.project.html\" xlink:title=\"Project(columns={&#39;type&#39;: &#39;string&#39;})\">\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"27\" cy=\"-19.799\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-16.999\" font-family=\"Times,serif\" font-size=\"11.00\">Project</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\n",
       "<g id=\"a_node4\"><a xlink:href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\" xlink:title=\"OneHot\">\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"117\" cy=\"-19.799\" rx=\"27\" ry=\"19.6\"/>\n",
       "<text text-anchor=\"middle\" x=\"117\" y=\"-22.999\" font-family=\"Times,serif\" font-size=\"11.00\">One&#45;</text>\n",
       "<text text-anchor=\"middle\" x=\"117\" y=\"-10.999\" font-family=\"Times,serif\" font-size=\"11.00\">Hot</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54.4029,-19.799C62.3932,-19.799 71.3106,-19.799 79.8241,-19.799\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"79.919,-23.2991 89.919,-19.799 79.919,-16.2991 79.919,-23.2991\"/>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M142.046,-27.4501C151.435,-30.4375 162.362,-33.9143 172.5,-37.1398\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"171.697,-40.5572 182.287,-40.2541 173.819,-33.8867 171.697,-40.5572\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\n",
       "<g id=\"a_node6\"><a xlink:title=\"XGBoost(colsample_bylevel=0.900172508121399, colsample_bytree=0.4645879165883061, learning_rate=0.3450371893786195, max_depth=10, min_child_weight=3, n_estimators=77, reg_alpha=0.9807177171317099, reg_lambda=0.5306129972505745, subsample=0.795703338311...\">\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"297\" cy=\"-47.799\" rx=\"27\" ry=\"19.6\"/>\n",
       "<text text-anchor=\"middle\" x=\"297\" y=\"-50.999\" font-family=\"Times,serif\" font-size=\"11.00\">XG&#45;</text>\n",
       "<text text-anchor=\"middle\" x=\"297\" y=\"-38.999\" font-family=\"Times,serif\" font-size=\"11.00\">Boost</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M234.403,-47.799C242.393,-47.799 251.311,-47.799 259.824,-47.799\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"259.919,-51.2991 269.919,-47.799 259.919,-44.2991 259.919,-51.2991\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fb13280d780>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lale.helpers.to_graphviz(auto_trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to inspect the results of automation is to pretty-print\n",
    "the trained pipeline back as Python source code. This lets us look at\n",
    "the output of automation in exactly the same syntax we used to specify\n",
    "the input to automation in the first place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "project = Project(columns={'type': 'number'})\n",
       "project_1 = Project_1(columns={'type': 'string'})\n",
       "xgboost = XGBoost(colsample_bylevel=0.900172508121399, colsample_bytree=0.4645879165883061, learning_rate=0.3450371893786195, max_depth=10, min_child_weight=3, n_estimators=77, reg_alpha=0.9807177171317099, reg_lambda=0.5306129972505745, subsample=0.7957033383112613)\n",
       "pipeline = ((project >> Norm) & (project_1 >> OneHot)) >> Concat >> xgboost\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import lale.pretty_print\n",
    "lale.pretty_print.ipython_display(auto_trained, show_imports=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bindings as Lifecycle\n",
    "\n",
    "The previous example already alluded to the notion of bindings and\n",
    "that those bindings are reflected in node visualization colors.\n",
    "Bindings here relate to the mathematical notion of free or bound\n",
    "variables in formulas. Bindings as lifecycle is one of the fundamental\n",
    "novel concepts around which we designed Lale. Lale distinguishes two\n",
    "kinds of operators: *individual operators* are data-science primitives\n",
    "such as data preprocessors or predictive models, whereas *pipelines*\n",
    "are compositions of operators. Each operator, whether individual or\n",
    "composite, can be in one of four lifecycle states: meta-model,\n",
    "planned, trainable, and trained. The lifecycle state of an operator is\n",
    "defined by which bindings it has. Specifically:\n",
    "\n",
    "- *Meta-model*: Individual operators at the meta-model state have\n",
    "  schemas and priors for their hyperparameters. Pipelines at the\n",
    "  meta-model state have steps (which are other operators) and a\n",
    "  grammar.\n",
    "\n",
    "- *Planned*: To get a planned pipeline, we need to *arrange* it by\n",
    "  binding a specific graph topology. This topology is consistent with\n",
    "  but more concrete than the steps and grammar from the meta-model\n",
    "  state.\n",
    "\n",
    "- *Trainable*: To get a trainable individual operator, we need to\n",
    "  initialize the concrete bindings for its hyperparameters.\n",
    "  Scikit-learn does this using `__init__`; Lale emulates that syntax\n",
    "  using `__call__`. To get a trainable pipeline, we need to bind\n",
    "  concrete operator choices given by the `|` combinator.\n",
    "\n",
    "- *Trained*: To get a trained individual operator, we need to *fit* it\n",
    "  to the data, thus binding its learnable coefficients. A trained\n",
    "  pipeline is like a trainable pipeline where all steps are trained.\n",
    "  More generally, the lifecycle state of a pipeline is limited by the\n",
    "  least upper bound of the states of its steps.\n",
    "\n",
    "<img src=\"img/2019-1105-bindings.png\" style=\"width:450px\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interested reader can explore Lale's concept of bindings as\n",
    "lifecycle in more detail in our\n",
    "[paper](https://arxiv.org/pdf/1906.03957.pdf).\n",
    "\n",
    "The above diagram is actually a Venn diagram. Each lifecycle state is\n",
    "a subset of its predecessor. For instance, a trained operator has all\n",
    "the bindings of a planned operator and in addition also binds learned\n",
    "coefficients. Since a trained operator has all bindings required for\n",
    "being a trainable operator, it can be used where a trainable operator\n",
    "is expected. This relationship between the lifecycle states is\n",
    "essential for offering a flexible semi-automated data science\n",
    "experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-Automated Data Science\n",
    "\n",
    "Why would data scientists not want full automation?  The main reason\n",
    "is to excert control over what kind of pipelines they find. Below is\n",
    "a summary of several scenarios motivating semi-automated data science.\n",
    "\n",
    "| Manual control over automation      | Examples |\n",
    "| ----------------------------------- | -------- |\n",
    "| Restrict available operator choices | Interpretable, or based on licenses, or based on GPU requirements, ... |\n",
    "| Tweak graph topology                | Custom preprocessing, or multi-modal data, or fairness mitigation, ... |\n",
    "| Tweak hyperparametrer schemas       | Adjust range for continuous, or restrict choices for categorical, ... |\n",
    "| Expand available operator choices   | Wrap existing library, or write your own operators, ... |\n",
    "\n",
    "In fact, we envision that this will often happen via trial-and-error,\n",
    "where you as the data scientist specify a first planned pipeline, let\n",
    "Auto-ML do its search, then inspect the results, edit your code, and\n",
    "try again. You already saw some of the Lale features for inspecting\n",
    "the results of automation above. Lale further support for this\n",
    "workflow by letting you specify *partial bindings* of some\n",
    "hyperparameters while allowing other to remain free, and by letting\n",
    "you *freeze* an operator at the trainable or trained state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 Newsgroups Dataset\n",
    "\n",
    "For the next examples in this notebook, we will need a different\n",
    "dataset. The following code fetches the 20 newsgroups data, using a\n",
    "function that comes with scikit-learn. Then, it prints a\n",
    "representative sample of the labels and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rec.autos</td>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sci.space</td>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       y                                                  X\n",
       "0              rec.autos  From: lerxst@wam.umd.edu (where's my thing)\\nS...\n",
       "1  comp.sys.mac.hardware  From: guykuo@carson.u.washington.edu (Guy Kuo)...\n",
       "2  comp.sys.mac.hardware  From: twillis@ec.ecn.purdue.edu (Thomas E Will...\n",
       "3          comp.graphics  From: jgreen@amber (Joe Green)\\nSubject: Re: W...\n",
       "4              sci.space  From: jcm@head-cfa.harvard.edu (Jonathan McDow..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.datasets\n",
    "news = sklearn.datasets.fetch_20newsgroups()\n",
    "news_X, news_y = news.data, news.target\n",
    "pd.DataFrame({'y': [news.target_names[i] for i in news_y], 'X': news_X}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels `y` are strings taken from a set of 20 different newsgroup\n",
    "names. That means that this is a 20-way classification dataset. The\n",
    "features `X` consist of a single string with a message posted to one\n",
    "of the newsgroups. The task is to use the message to predict which\n",
    "group it was posted on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraints in Scikit-learn\n",
    "\n",
    "As implied by the title of this notebook and the corresponding talk,\n",
    "Lale is built around the concept of types. In programming languages, a\n",
    "*type* specifies a set of valid values for a variable (e.g., for a\n",
    "hyperparameter).  While types are in the foreground of some\n",
    "programming languages, they are more in the background in\n",
    "Python. Python is dynamically typed, and libraries such as\n",
    "scikit-learn rely more on exceptions than on types for their error\n",
    "checking. To demonstrate this, we first import some scikit-learn\n",
    "modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.feature_extraction.text\n",
    "import sklearn.pipeline\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a scikit-learn pipeline, using fully qualified names\n",
    "to ensure and clarify that we are not using any Lale facilities. The\n",
    "pipeline consists of just two operators, a TFIDF transformer for\n",
    "extracting features from the message text followed by a\n",
    "LogisticRegression for classifying the message by newsgroup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no error detected yet\n"
     ]
    }
   ],
   "source": [
    "sklearn_misconfigured = sklearn.pipeline.make_pipeline(\n",
    "    sklearn.feature_extraction.text.TfidfVectorizer(),\n",
    "    sklearn.linear_model.LogisticRegression(solver='sag', penalty='l1'))\n",
    "print('no error detected yet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code actually contains a mistake in the hyperparameters for\n",
    "LogisticRegression. Unfortunately, scikit-learn does not detect this\n",
    "mistake when the hyperparameters are configured in the code. Instead,\n",
    "it delays its error checking until we attempt to fit the pipeline to\n",
    "data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.95 s, sys: 250 ms, total: 5.2 s\n",
      "Wall time: 5.52 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solver sag supports only l2 penalties, got l1 penalty.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sys\n",
    "try:\n",
    "    sklearn_misconfigured.fit(news_X, news_y)\n",
    "except ValueError as e:\n",
    "    print(e, file=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output demonstrates that scikit-learn takes a few seconds to\n",
    "report the error. This is because it first trains the TFIDF\n",
    "transformer on the data, and only when that is done, it attempts to\n",
    "train the LogisticRegression, triggering the exception. A few seconds\n",
    "are no big deal, but the 20 newsgroup dataset is small. For larger\n",
    "datasets, the delay is larger. Furthermore, while in this case, the\n",
    "erroneous code is not far away from the code that triggers the error\n",
    "report, for larger code bases, that distance is also further. The\n",
    "error message is nice and clear about the erroneous hyperpareters, but\n",
    "does not mention which operator was misconfigured (here,\n",
    "LogisticRegression)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraints in Auto-ML\n",
    "\n",
    "The above example illustrates an exception caused by manually\n",
    "misconfigured hyperparameters. Tools for automated machine learning\n",
    "usually run many trials with different hyperparameter configurations.\n",
    "Just as in the manual case, in general, some of these automated trials\n",
    "may raise exceptions.\n",
    "\n",
    "**Solution 1:** Unconstrained search space\n",
    "\n",
    "- {solver: \\[linear, sag, lbfgs\\], penalty: \\[l1, l2\\]}\n",
    "- catch exception (after some time)\n",
    "- return made-up loss `np.float.max`\n",
    "\n",
    "This first solution has the benefit of being simple, but the drawback\n",
    "that it may waste computational resources on training upstream\n",
    "operators before detecting erroneous downstream operators. It also\n",
    "leads to a larger-than-necessary search space. While we can use a high\n",
    "loss to steer the Auto-ML tool away from poorly performing points in\n",
    "the search space, we have seen cases where this adversely affect its\n",
    "convergence.\n",
    "\n",
    "**Solution 2:** Constrained search space\n",
    "\n",
    "- {solver: \\[linear, sag, lbfgs\\], penalty: \\[l1, l2]\\} **and** (**if** solver: [sag, lbfgs] **then** penalty: [l2])}\n",
    "- no exceptions (no time wasted)\n",
    "- no made-up loss\n",
    "\n",
    "The second solution is the one we advocate in Lale. The Lale library\n",
    "contains hyperparameter schemas for a large number of operators. These\n",
    "schemas are type specifications that encode not just the valid values\n",
    "for each hyperparameter in isolation, but also constraints cutting\n",
    "across multiple hyperparameters such as `solver` and `penalty` in the\n",
    "example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraints in Lale\n",
    "\n",
    "To demonstrate how Lale handles constraints, we first import Lale's\n",
    "wrapper for TFIDF. We need not import LogisticRegression here since we\n",
    "already imported it earlier in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lale.lib.sklearn import TfidfVectorizer as Tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lale uses JSON Schema to express types. JSON Schema is a widely\n",
    "supported and adopted standard proposal for specifying the valid\n",
    "structure of JSON documents. By using JSON Schema for hyperparameters,\n",
    "we avoided the need to implement any custom schema validation code.\n",
    "Instead, we simply put the concrete hyperparameters into a JSON\n",
    "document and then use an off-the-shelf validator to check that against\n",
    "the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.2 ms, sys: 15.6 ms, total: 46.9 ms\n",
      "Wall time: 28.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid configuration for LR(solver='sag', penalty='l1') due to constraint the newton-cg, sag, and lbfgs solvers support only l2 penalties.\n",
      "Schema of constraint 1: {\n",
      "    'description': 'The newton-cg, sag, and lbfgs solvers support only l2 penalties.',\n",
      "    'anyOf': [{\n",
      "        'type': 'object',\n",
      "        'properties': {\n",
      "            'solver': {\n",
      "                'not': {\n",
      "                    'enum': ['newton-cg', 'sag', 'lbfgs']}}}}, {\n",
      "        'type': 'object',\n",
      "        'properties': {\n",
      "            'penalty': {\n",
      "                'enum': ['l2']}}}],\n",
      "}\n",
      "Value: {'solver': 'sag', 'penalty': 'l1', 'dual': False, 'C': 1.0, 'tol': 0.0001, 'fit_intercept': True, 'intercept_scaling': 1.0, 'class_weight': None, 'random_state': None, 'max_iter': 100, 'multi_class': 'ovr', 'verbose': 0, 'warm_start': False, 'n_jobs': None}\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import jsonschema\n",
    "try:\n",
    "    lale_misconfigured = Tfidf >> LR(LR.solver.sag, LR.penalty.l1)\n",
    "except jsonschema.ValidationError as e:\n",
    "    print(e.message, file=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output demonstrates that the error check happened more than 100\n",
    "times faster than in the previous example. This is because the code\n",
    "did not need to train TFIDF. The error check also happened closer to\n",
    "the root cause of the error. Furthermore, the error message indicates\n",
    "not just the wrong hyperparameters but also which operator was\n",
    "misconfigured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schemas as Documentation\n",
    "\n",
    "The above code example demonstrated that Lale uses JSON Schema for\n",
    "error checking. Since all Lale operators carry hyperparameter schemas,\n",
    "we can also use those same schemas for interactive documentation.  The\n",
    "following code illustrates that by inspecting the schema of a\n",
    "continuous hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Number of trees to fit.',\n",
       " 'type': 'integer',\n",
       " 'default': 100,\n",
       " 'minimumForOptimizer': 10,\n",
       " 'maximumForOptimizer': 1500}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBoost.hyperparam_schema('n_estimators')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the same interactive documentation approach also works for\n",
    "categorical hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Specify which booster to use.',\n",
       " 'enum': ['gbtree', 'gblinear', 'dart'],\n",
       " 'default': 'gbtree'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBoost.hyperparam_schema('booster')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same schemas for two purposes (validation and documentation)\n",
    "makes them stronger. As a user, you can be confident that the\n",
    "documentation you read is in sync with the error checks in the code.\n",
    "Furthermore, while schemas check hyperparameters, the reverse is also\n",
    "true: when tests reveal mistakes in the schemas themselves, they will\n",
    "be corrected in a single location, thus improving both validation and\n",
    "documentation.  However, we can do even better than using the same\n",
    "schemas for two purposes: we can also use them for a third purpose\n",
    "(automated search)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types as Search Spaces\n",
    "\n",
    "<img src=\"img/2019-1105-search-spaces.png\" style=\"width:550px\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lale.schemas as schemas\n",
    "Grove = XGBoost.customize_schema(\n",
    "    n_estimators=schemas.Int(min=2, max=6),\n",
    "    booster=schemas.Enum(['gbtree']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "grove_planned = ( Project(columns={'type': 'number'}) >> Norm\n",
    "                & Project(columns={'type': 'string'}) >> OneHot\n",
    "                ) >> Concat >> Grove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:29<00:00,  2.71s/it, best loss: -0.7358263933376041]\n",
      "accuracy 71.2%\n"
     ]
    }
   ],
   "source": [
    "grove_optimizer = HyperoptClassifier(grove_planned, cv=3, max_evals=10)\n",
    "grove_trained = grove_optimizer.fit(train_X, train_y)\n",
    "grove_y = grove_trained.predict(test_X)\n",
    "print(f'accuracy {sklearn.metrics.accuracy_score(test_y, grove_y):.1%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "project = Project(columns={'type': 'number'})\n",
       "norm = Norm(norm='max')\n",
       "project_1 = Project_1(columns={'type': 'string'})\n",
       "xgboost = XGBoost(booster='gbtree', colsample_bylevel=0.6016063807304212, colsample_bytree=0.7763972782064467, learning_rate=0.16389357351003786, max_depth=10, min_child_weight=5, n_estimators=4, reg_alpha=0.10485915855270356, reg_lambda=0.9268502695024392, subsample=0.4503841871781402)\n",
       "pipeline = ((project >> norm) & (project_1 >> OneHot)) >> Concat >> xgboost\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lale.pretty_print.ipython_display(grove_trained, show_imports=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn Compatible Interoperability\n",
    "\n",
    "<img src=\"img/2019-1105-interop.png\" style=\"width:550px\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Examples, documentation, code: https://github.com/ibm/lale\n",
    "\n",
    "<img src=\"img/2019-1105-summary.png\" style=\"width:350px\" align=\"left\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
