{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lale: Auto-ML and Types for Scikit-learn\n",
    "\n",
    "This notebook is an introductory guide to\n",
    "[Lale](https://github.com/ibm/lale) for scikit-learn users.\n",
    "[Scikit-learn](https://scikit-learn.org) is a popular, easy-to-use,\n",
    "and comprehensive data science library for Python. This notebook aims\n",
    "to show how Lale can make scikit-learn even better in two areas:\n",
    "auto-ML and type checking. First, if you do not want to manually\n",
    "select all algorithms or tune all hyperparameters, you can leave it to\n",
    "Lale to do that for you automatically.  Second, when you pass\n",
    "hyperparameters or datasets to scikit-learn, Lale checks that these\n",
    "are type-correct.  For both auto-ML and type-checking, Lale uses a\n",
    "single source of truth: machine-readable schemas associated with\n",
    "scikit-learn compatible transformers and estimators. Rather than\n",
    "invent a new schema specification language, Lale uses [JSON\n",
    "Schema](https://json-schema.org/understanding-json-schema/), because\n",
    "it is popular, widely-supported, and makes it easy to store or send\n",
    "hyperparameters as JSON objects. Furthermore, by using the same\n",
    "schemas both for auto-ML and for type-checking, Lale ensures that\n",
    "auto-ML is consistent with type checking while also reducing the\n",
    "maintenance burden to a single set of schemas.\n",
    "\n",
    "Lale is an open-source Python library and you can install it by doing\n",
    "`pip install lale`. See\n",
    "[installation](https://github.com/IBM/lale/blob/master/docs/installation.rst)\n",
    "for further instructions. Lale uses the term *operator* to refer to\n",
    "what scikit-learn calls machine-learning transformer or estimator.\n",
    "Lale provides schemas for 144\n",
    "[operators](https://github.com/IBM/lale/tree/master/lale/lib). Most of\n",
    "these operators come from scikit-learn itself, but there are also\n",
    "operators from other frameworks such as XGBoost or PyTorch.\n",
    "If Lale does not yet support your favorite operator, you can add it\n",
    "yourself by following this\n",
    "[guide](https://nbviewer.jupyter.org/github/IBM/lale/blob/master/examples/docs_new_operators.ipynb).\n",
    "If you do add a new operator, please consider contributing it back to\n",
    "Lale!\n",
    "\n",
    "The rest of this notebook first demonstrates auto-ML, then reveals\n",
    "some of the schemas that make that possible, and finally demonstrates\n",
    "how to also use the very same schemas for type checking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Auto-ML with Lale\n",
    "\n",
    "Lale serves as an interface for two Auto-ML tasks: hyperparameter tuning\n",
    "and algorithm selection. Rather than provide new implementations for\n",
    "these tasks, Lale reuses existing implementations. The next few cells\n",
    "demonstrate how to use hyperopt and GridSearchCV from Lale. Lale also\n",
    "supports additional optimizers, not shown in this notebook. In all\n",
    "cases, the syntax for specifying the search space is the same.\n",
    "\n",
    "### 1.1 Hyperparameter Tuning with Lale and Hyperopt\n",
    "\n",
    "Let's start by looking at hyperparameter tuning, which is an important\n",
    "subtask of auto-ML. To demonstrate it, we first need a dataset.\n",
    "Therefore, we load the California Housing dataset and display the\n",
    "first few rows to get a feeling for the data. Lale can process both\n",
    "Pandas dataframes and Numpy ndarrays; here we use dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.2596</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5.017657</td>\n",
       "      <td>1.006421</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>3.691814</td>\n",
       "      <td>32.71</td>\n",
       "      <td>-117.03</td>\n",
       "      <td>1.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.8125</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4.473545</td>\n",
       "      <td>1.041005</td>\n",
       "      <td>1314.0</td>\n",
       "      <td>1.738095</td>\n",
       "      <td>33.77</td>\n",
       "      <td>-118.16</td>\n",
       "      <td>3.821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.1563</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.645833</td>\n",
       "      <td>0.985119</td>\n",
       "      <td>915.0</td>\n",
       "      <td>2.723214</td>\n",
       "      <td>34.66</td>\n",
       "      <td>-120.48</td>\n",
       "      <td>1.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.9425</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4.002817</td>\n",
       "      <td>1.033803</td>\n",
       "      <td>1418.0</td>\n",
       "      <td>3.994366</td>\n",
       "      <td>32.69</td>\n",
       "      <td>-117.11</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.5542</td>\n",
       "      <td>43.0</td>\n",
       "      <td>6.268421</td>\n",
       "      <td>1.134211</td>\n",
       "      <td>874.0</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>36.78</td>\n",
       "      <td>-119.80</td>\n",
       "      <td>0.965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  3.2596      33.0  5.017657   1.006421      2300.0  3.691814     32.71   \n",
       "1  3.8125      49.0  4.473545   1.041005      1314.0  1.738095     33.77   \n",
       "2  4.1563       4.0  5.645833   0.985119       915.0  2.723214     34.66   \n",
       "3  1.9425      36.0  4.002817   1.033803      1418.0  3.994366     32.69   \n",
       "4  3.5542      43.0  6.268421   1.134211       874.0  2.300000     36.78   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -117.03   1.030  \n",
       "1    -118.16   3.821  \n",
       "2    -120.48   1.726  \n",
       "3    -117.11   0.934  \n",
       "4    -119.80   0.965  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lale.datasets\n",
    "(train_X, train_y), (test_X, test_y) = lale.datasets.california_housing_df()\n",
    "pd.concat([train_X.head(), train_y.head()], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the target column is a continuous number, indicating\n",
    "that this is a regression task. Besides the target, there are eight\n",
    "feature columns, which are also all continuous numbers. That means\n",
    "many scikit-learn operators will work out of the box on this data\n",
    "without needing to preprocess it first. Next, we need to import a few\n",
    "operators. `PCA` (principal component analysis) is a transformer from\n",
    "scikit-learn for linear dimensionality reduction.\n",
    "`DecisionTreeRegressor` is an estimator from scikit-learn that can\n",
    "predict the target column.  `HyperoptRegressor` is a Lale wrapper for\n",
    "the [hyperopt](http://hyperopt.github.io/hyperopt/) auto-ML library.\n",
    "And finally, `wrap_imported_operators` augments both `PCA` and `Tree`\n",
    "with schemas to enable Lale to tune their hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeRegressor as Tree\n",
    "from lale.lib.lale import HyperoptRegressor\n",
    "import lale.helpers\n",
    "lale.helpers.wrap_imported_operators()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a two-step pipeline of `PCA` and `Tree`.  Scikit-learn\n",
    "has a function `make_pipeline` and Lale provides the same\n",
    "functionality. The only difference compared to a scikit-learn pipeline\n",
    "is that since we want Lale to tune the hyperparameters for us, we do\n",
    "not specify them by hand. Specifically, we just write `PCA` instead of\n",
    "`PCA(...)`, omitting the hyperparameters for `PCA`. Analogously, we\n",
    "just write `Tree` instead of `Tree(...)`, omitting the hyperparameters\n",
    "for `Tree`. Rather than binding hyperparameters by hand, we leave them\n",
    "free to be tuned by hyperopt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_tree_planned = lale.operators.make_pipeline(PCA, Tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we create an instance of `HyperoptRegressor`, we pass in the\n",
    "pipeline as its `estimator` argument. Then, we call `fit` to search\n",
    "for a good pipeline. In this case, the search uses 10 trials. Each\n",
    "trial draws values for the hyperparameters from the ranges specified\n",
    "by the JSON schemas associated with the operators in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:24<00:00, 11.11s/it, best loss: 0.38148615225744564]\n",
      "CPU times: user 1min 36s, sys: 11.3 s, total: 1min 47s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pca_tree_hyperopt = HyperoptRegressor(estimator=pca_tree_planned, cv=3, max_evals=10)\n",
    "pca_tree_trained = pca_tree_hyperopt.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, HyperoptRegressor uses k-fold cross validation with the R2\n",
    "score to evaluate each trial. The end result is the pipeline that\n",
    "performed best out of all trials.  In addition to the cross-val score,\n",
    "we can also evaluate this best pipeline against the test data. We\n",
    "simply use the existing R2 score metric from scikit-learn for this\n",
    "purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score 0.60\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "predicted = pca_tree_trained.predict(test_X)\n",
    "print(f'R2 score {sklearn.metrics.r2_score(test_y, predicted):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Inspecting the Results of Automation\n",
    "\n",
    "In the previous example, the automation picked hyperparameter values\n",
    "for PCA and the decision tree. We know the values were valid and we\n",
    "know how well the pipeline performed with them. But we might also want\n",
    "to know exactly which values were picked. One way to do that is by\n",
    "visualizing the pipeline and using tooltips. If you are looking at\n",
    "this notebook in a viewer that supports tooltips, you can hover the\n",
    "mouse pointer over either one of the operators to see its\n",
    "hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"152pt\" height=\"44pt\"\n",
       " viewBox=\"0.00 0.00 152.00 44.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 40)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-40 148,-40 148,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<g id=\"a_node1\"><a xlink:href=\"https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\" xlink:title=\"PCA(svd_solver=&#39;arpack&#39;, whiten=True)\">\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-15.2\" font-family=\"Times,serif\" font-size=\"11.00\">PCA</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\n",
       "<g id=\"a_node2\"><a xlink:href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\" xlink:title=\"Tree(criterion=&#39;mae&#39;, min_samples_leaf=3, min_samples_split=19, splitter=&#39;random&#39;)\">\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"117\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"117\" y=\"-15.2\" font-family=\"Times,serif\" font-size=\"11.00\">Tree</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54.4029,-18C62.3932,-18 71.3106,-18 79.8241,-18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"79.919,-21.5001 89.919,-18 79.919,-14.5001 79.919,-21.5001\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f140531b198>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lale.helpers import best_estimator\n",
    "lale.helpers.to_graphviz(best_estimator(pca_tree_trained))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to view the results of hyperparameter tuning in Lale is by\n",
    "pretty-printing the pipeline as Python source code.  Lale provides a\n",
    "helper function `ipython_display` that pretty-prints pipelines with\n",
    "syntax highlighting in a Jupyter notebook.  The pretty-printed code\n",
    "contains the hyperparameters. It also uses the `>>` symbol, which is\n",
    "just syntactic sugar for calling the `make_pipeline` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "pca = PCA(svd_solver='arpack', whiten=True)\n",
       "tree = Tree(criterion='mae', min_samples_leaf=3, min_samples_split=19, splitter='random')\n",
       "pipeline = pca >> tree\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lale.pretty_print import ipython_display\n",
    "ipython_display(best_estimator(pca_tree_trained), show_imports=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Hyperparameter Tuning with Lale and GridSearchCV\n",
    "\n",
    "Lale supports multiple auto-ML tools, not just hyperopt. For instance,\n",
    "you can also use\n",
    "[GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "from scikit-learn. You can use the exact same `pca_tree_planned`\n",
    "pipeline for this as we did with the hyperopt tool. Lale again uses\n",
    "the schemas attached to the operators in the pipeline to generate a\n",
    "suitable search grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lale.lib.lale import GridSearchCV\n",
    "grid_search_grid = GridSearchCV(\n",
    "    estimator=pca_tree_planned, lale_num_samples=1, lale_num_grids=1, cv=3,\n",
    "    scoring=sklearn.metrics.make_scorer(sklearn.metrics.r2_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the search, you call `fit` and provide the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37 s, sys: 15.5 s, total: 52.5 s\n",
      "Wall time: 27.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_search_result = grid_search_grid.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like we saw earlier with hyperopt, you can use the best pipeline\n",
    "found for scoring and evaluate the quality of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score 0.51\n"
     ]
    }
   ],
   "source": [
    "grid_search_best = best_estimator(grid_search_result)\n",
    "predicted = grid_search_best.predict(test_X)\n",
    "print(f'R2 score {sklearn.metrics.r2_score(test_y, predicted):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, to inspect the results of grid search, you have the same\n",
    "options as demonstrated earlier for hypopt. For instance, you can\n",
    "pretty-print the best pipeline found by grid search back as Python\n",
    "source code, and then look at its hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "pca = PCA(svd_solver='randomized', whiten=True)\n",
       "tree = Tree(max_features=5e-324, min_samples_leaf=0.01, min_samples_split=0.01)\n",
       "pipeline = pca >> tree\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipython_display(grid_search_best, show_imports=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Pipeline Combinators\n",
    "\n",
    "We already saw that `>>` is syntactic sugar for `make_pipeline`.  Lale\n",
    "refers to `>>` as the *pipe combinator*. Besides `>>`, Lale supports\n",
    "two additional combinators. Before we introduce them, let's import a\n",
    "few more things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lale.lib.lale import NoOp, ConcatFeatures\n",
    "from sklearn.linear_model import LinearRegression as LinReg\n",
    "from xgboost import XGBRegressor as XGBoost\n",
    "lale.helpers.wrap_imported_operators()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lale emulates the scikit-learn APIs for composing pipelines using\n",
    "functions. We already saw `make_pipeline`. Another function in\n",
    "scikit-learn is `make_union`, which composes multiple sub-pipelines to\n",
    "run on the same data, then concatenates the features. In other words,\n",
    "`make_union` produces a horizontal stack of the data transformed by\n",
    "its sub-pipelines. To support auto-ML, Lale introduces a third\n",
    "function, `make_choice`, which does not exist in scikit-learn. The\n",
    "`make_choice` function specifies an algorithmic choice for auto-ML to\n",
    "resolve. In other words, `make_choice` creates a search space for\n",
    "automated algorithm selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"336pt\" height=\"102pt\"\n",
       " viewBox=\"0.00 0.00 335.54 101.80\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 97.799)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-97.799 331.542,-97.799 331.542,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<g id=\"a_node1\"><a xlink:href=\"https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\" xlink:title=\"PCA\">\n",
       "<ellipse fill=\"#7ec0ee\" stroke=\"black\" cx=\"27\" cy=\"-75.799\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-72.999\" font-family=\"Times,serif\" font-size=\"11.00\">PCA</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\n",
       "<g id=\"a_node3\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.lale.concat_features.html\" xlink:title=\"ConcatFeatures\">\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"123.234\" cy=\"-47.799\" rx=\"33.4697\" ry=\"19.6\"/>\n",
       "<text text-anchor=\"middle\" x=\"123.234\" y=\"-50.999\" font-family=\"Times,serif\" font-size=\"11.00\">Concat&#45;</text>\n",
       "<text text-anchor=\"middle\" x=\"123.234\" y=\"-38.999\" font-family=\"Times,serif\" font-size=\"11.00\">Features</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M52.2676,-68.5883C61.6899,-65.7886 72.7207,-62.511 83.2014,-59.3969\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"84.4219,-62.6855 93.0108,-56.4822 82.4281,-55.9754 84.4219,-62.6855\"/>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\n",
       "<g id=\"a_node2\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.lale.no_op.html\" xlink:title=\"NoOp\">\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"27\" cy=\"-19.799\" rx=\"27\" ry=\"19.6\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-22.999\" font-family=\"Times,serif\" font-size=\"11.00\">No&#45;</text>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-10.999\" font-family=\"Times,serif\" font-size=\"11.00\">Op</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M52.2676,-27.0097C61.6899,-29.8093 72.7207,-33.087 83.2014,-36.2011\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"82.4281,-39.6225 93.0108,-39.1158 84.4219,-32.9125 82.4281,-39.6225\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\n",
       "<g id=\"a_node4\"><a xlink:title=\"Tree | LinReg | XGBoost\">\n",
       "<ellipse fill=\"#7ec0ee\" stroke=\"black\" cx=\"260.005\" cy=\"-47.799\" rx=\"67.5738\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"260.005\" y=\"-44.999\" font-family=\"Times,serif\" font-size=\"11.00\">Tree | LinReg | XGBoost</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M156.515,-47.799C164.38,-47.799 173.129,-47.799 182.109,-47.799\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"182.31,-51.2991 192.31,-47.799 182.31,-44.2991 182.31,-51.2991\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f1406d8d400>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dag_with_functions = lale.operators.make_pipeline(\n",
    "    lale.operators.make_union(PCA, NoOp),\n",
    "    lale.operators.make_choice(Tree, LinReg, XGBoost))\n",
    "lale.helpers.to_graphviz(dag_with_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualization shows `make_union` as multiple sub-pipelines feeding\n",
    "into `ConcatFeatures`, and it shows `make_choice` using an `|`\n",
    "combinator.  Operators shown in white are already fully trained; in\n",
    "this case, these operators actually do not have any learnable\n",
    "coefficients, nor do they have hyperparameters. For each of the three\n",
    "functions `make_pipeline`, `make_choice`, and `make_union`, Lale also\n",
    "provides a corresponding combinator. We already saw the pipe\n",
    "combinator (`>>`) and the choice combinator (`|`).  To get the effect\n",
    "of `make_union`, use the *and combinator* (`&`) with the\n",
    "`ConcatFeatures` operator. The next example shows the exact same\n",
    "pipeline as before, but written using combinators instead of\n",
    "functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"336pt\" height=\"102pt\"\n",
       " viewBox=\"0.00 0.00 335.54 101.80\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 97.799)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-97.799 331.542,-97.799 331.542,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<g id=\"a_node1\"><a xlink:href=\"https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\" xlink:title=\"PCA\">\n",
       "<ellipse fill=\"#7ec0ee\" stroke=\"black\" cx=\"27\" cy=\"-75.799\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-72.999\" font-family=\"Times,serif\" font-size=\"11.00\">PCA</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\n",
       "<g id=\"a_node3\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.lale.concat_features.html\" xlink:title=\"ConcatFeatures\">\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"123.234\" cy=\"-47.799\" rx=\"33.4697\" ry=\"19.6\"/>\n",
       "<text text-anchor=\"middle\" x=\"123.234\" y=\"-50.999\" font-family=\"Times,serif\" font-size=\"11.00\">Concat&#45;</text>\n",
       "<text text-anchor=\"middle\" x=\"123.234\" y=\"-38.999\" font-family=\"Times,serif\" font-size=\"11.00\">Features</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M52.2676,-68.5883C61.6899,-65.7886 72.7207,-62.511 83.2014,-59.3969\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"84.4219,-62.6855 93.0108,-56.4822 82.4281,-55.9754 84.4219,-62.6855\"/>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\n",
       "<g id=\"a_node2\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.lale.no_op.html\" xlink:title=\"NoOp\">\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"27\" cy=\"-19.799\" rx=\"27\" ry=\"19.6\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-22.999\" font-family=\"Times,serif\" font-size=\"11.00\">No&#45;</text>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-10.999\" font-family=\"Times,serif\" font-size=\"11.00\">Op</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M52.2676,-27.0097C61.6899,-29.8093 72.7207,-33.087 83.2014,-36.2011\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"82.4281,-39.6225 93.0108,-39.1158 84.4219,-32.9125 82.4281,-39.6225\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\n",
       "<g id=\"a_node4\"><a xlink:title=\"Tree | LinReg | XGBoost\">\n",
       "<ellipse fill=\"#7ec0ee\" stroke=\"black\" cx=\"260.005\" cy=\"-47.799\" rx=\"67.5738\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"260.005\" y=\"-44.999\" font-family=\"Times,serif\" font-size=\"11.00\">Tree | LinReg | XGBoost</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M156.515,-47.799C164.38,-47.799 173.129,-47.799 182.109,-47.799\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"182.31,-51.2991 192.31,-47.799 182.31,-44.2991 182.31,-51.2991\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f1403a484a8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dag_with_combinators = (\n",
    "       (PCA & NoOp)\n",
    "    >> ConcatFeatures\n",
    "    >> (Tree | LinReg | XGBoost))\n",
    "lale.helpers.to_graphviz(dag_with_combinators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Combined Algorithm Selection and Hyperparameter Optimization\n",
    "\n",
    "Since the `dag_with_functions` specifies an algorithm choice, when we\n",
    "feed it to a `HyperoptRegressor`, hyperopt will do algorithm selection\n",
    "for us. And since some of the operators in the dag do not have all\n",
    "their hyperparameters bound, hyperopt will also tune their free\n",
    "hyperparameters for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:53<00:00,  9.22s/it, best loss: 0.22219402067079008]\n",
      "CPU times: user 2min 19s, sys: 13.1 s, total: 2min 32s\n",
      "Wall time: 2min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "multi_alg_hyperopt = HyperoptRegressor(estimator=dag_with_functions, cv=3, max_evals=10)\n",
    "multi_alg_trained = multi_alg_hyperopt.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the best estimator reveals what algorithms\n",
    "hyperopt chose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"254pt\" height=\"102pt\"\n",
       " viewBox=\"0.00 0.00 254.47 101.80\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 97.799)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-97.799 250.468,-97.799 250.468,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<g id=\"a_node1\"><a xlink:href=\"https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\" xlink:title=\"PCA(n_components=&#39;mle&#39;, svd_solver=&#39;full&#39;)\">\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"27\" cy=\"-75.799\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-72.999\" font-family=\"Times,serif\" font-size=\"11.00\">PCA</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\n",
       "<g id=\"a_node3\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.lale.concat_features.html\" xlink:title=\"ConcatFeatures\">\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"123.234\" cy=\"-47.799\" rx=\"33.4697\" ry=\"19.6\"/>\n",
       "<text text-anchor=\"middle\" x=\"123.234\" y=\"-50.999\" font-family=\"Times,serif\" font-size=\"11.00\">Concat&#45;</text>\n",
       "<text text-anchor=\"middle\" x=\"123.234\" y=\"-38.999\" font-family=\"Times,serif\" font-size=\"11.00\">Features</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M52.2676,-68.5883C61.6899,-65.7886 72.7207,-62.511 83.2014,-59.3969\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"84.4219,-62.6855 93.0108,-56.4822 82.4281,-55.9754 84.4219,-62.6855\"/>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\n",
       "<g id=\"a_node2\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.lale.no_op.html\" xlink:title=\"NoOp\">\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"27\" cy=\"-19.799\" rx=\"27\" ry=\"19.6\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-22.999\" font-family=\"Times,serif\" font-size=\"11.00\">No&#45;</text>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-10.999\" font-family=\"Times,serif\" font-size=\"11.00\">Op</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M52.2676,-27.0097C61.6899,-29.8093 72.7207,-33.087 83.2014,-36.2011\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"82.4281,-39.6225 93.0108,-39.1158 84.4219,-32.9125 82.4281,-39.6225\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\n",
       "<g id=\"a_node4\"><a xlink:href=\"https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn\" xlink:title=\"XGBoost(colsample_bylevel=0.8125953277265251, colsample_bytree=0.7432005864418613, learning_rate=0.336632702036662, max_depth=4, min_child_weight=8, n_estimators=1012, reg_alpha=0.02223895190558911, reg_lambda=0.02984096814184546, subsample=0.498939586...\">\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"219.468\" cy=\"-47.799\" rx=\"27\" ry=\"19.6\"/>\n",
       "<text text-anchor=\"middle\" x=\"219.468\" y=\"-50.999\" font-family=\"Times,serif\" font-size=\"11.00\">XG&#45;</text>\n",
       "<text text-anchor=\"middle\" x=\"219.468\" y=\"-38.999\" font-family=\"Times,serif\" font-size=\"11.00\">Boost</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M156.664,-47.799C164.825,-47.799 173.638,-47.799 181.983,-47.799\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"182.217,-51.2991 192.217,-47.799 182.217,-44.2991 182.217,-51.2991\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f148c1858d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lale.helpers.to_graphviz(best_estimator(multi_alg_trained))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty-printing the best estiamtor reveals how hyperopt tuned the\n",
    "hyperparameters. For instance, we can see that XGBoost picked a forest\n",
    "with a large number `n_estimators` of trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "pca = PCA(n_components='mle', svd_solver='full')\n",
       "xgboost = XGBoost(colsample_bylevel=0.8125953277265251, colsample_bytree=0.7432005864418613, learning_rate=0.336632702036662, max_depth=4, min_child_weight=8, n_estimators=1012, reg_alpha=0.02223895190558911, reg_lambda=0.02984096814184546, subsample=0.498939586636504)\n",
       "pipeline = (pca & NoOp) >> ConcatFeatures >> xgboost\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipython_display(best_estimator(multi_alg_trained), show_imports=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the trained pipeline can be used for predictions as usual,\n",
    "and we can use scikit-learn metrics to evaluate those predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score 0.79\n"
     ]
    }
   ],
   "source": [
    "predicted = multi_alg_trained.predict(test_X)\n",
    "print(f'R2 score {sklearn.metrics.r2_score(test_y, predicted):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Viewing and Customizing Schemas\n",
    "\n",
    "This section reveals more of what happens behind the scenes for\n",
    "auto-ML with Lale. In particular, it shows the JSON Schemas used for\n",
    "auto-ML, and demonstrates how to customize them if desired.\n",
    "\n",
    "### 2.1 Looking at Schemas from a Notebook\n",
    "\n",
    "When writing data science code, I often don't remember all the API\n",
    "information about what hyperparameters and datasets an operator\n",
    "expects.  Lale attaches this information to the operators and uses it\n",
    "for auto-ML as demonstrated above. The same information can also be\n",
    "useful as interactive documentation in a notebook. Most individual\n",
    "operators in the visualizations shown earlier in this notebook actually\n",
    "contain a hyperlink to the excellent online documentation of\n",
    "scikit-learn. We can also retrieve that hyperlink using a method call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n"
     ]
    }
   ],
   "source": [
    "print(Tree.documentation_url())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lale's helper function `ipython_display` pretty-prints JSON documents\n",
    "and JSON schemas in a Jupyter notebook. You can get a quick overview\n",
    "of the constructor arguments of an operator by calling the\n",
    "`hyperparam_defaults` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "{\n",
       "    'criterion': 'mse',\n",
       "    'splitter': 'best',\n",
       "    'max_depth': null,\n",
       "    'min_samples_split': 2,\n",
       "    'min_samples_leaf': 1,\n",
       "    'min_weight_fraction_leaf': 0.0,\n",
       "    'max_features': null,\n",
       "    'random_state': null,\n",
       "    'max_leaf_nodes': null,\n",
       "    'min_impurity_decrease': 0.0,\n",
       "    'min_impurity_split': null,\n",
       "    'presort': false}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipython_display(Tree.hyperparam_defaults())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters can be categorical (meaning they accept a few\n",
    "discrete values) or continuous (integers or real numbers).\n",
    "As an example for a categorical hyperparameter, let's look at the\n",
    "`criterion`. JSON Schema can encode categoricals as an `enum`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "{\n",
       "    'description': 'Function to measure the quality of a split.',\n",
       "    'enum': ['mse', 'friedman_mse', 'mae'],\n",
       "    'default': 'mse'}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipython_display(Tree.hyperparam_schema('criterion'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example for a continuous hyperparameter, let's look at\n",
    "`max_depth`. The decision tree regressor in scikit-learn accepts\n",
    "either an integer for that, or `None`, which has its own meaning.\n",
    "JSON Schema can express these two choices as an `anyOf`, and\n",
    "encodes the Python `None` as a JSON `null`.  Also, while\n",
    "any positive integer is a valid value, in the context of auto-AI,\n",
    "Lale specifies a bounded range for the optimizer to search over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "{\n",
       "    'description': 'Maximum depth of the tree.',\n",
       "    'default': null,\n",
       "    'anyOf': [\n",
       "    {   'type': 'integer',\n",
       "        'minimum': 1,\n",
       "        'minimumForOptimizer': 3,\n",
       "        'maximumForOptimizer': 5},\n",
       "    {   'enum': [null],\n",
       "        'description': 'If None, then nodes are expanded until all leaves are pure, or until all leaves contain less than min_samples_split samples.'}]}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipython_display(Tree.hyperparam_schema('max_depth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides hyperparameter schemas, Lale also provides dataset schemas.\n",
    "For exampe, NMF, which stands for non-negative matrix factorization,\n",
    "requires a non-negative matrix as `X`. In JSON Schema, we express this\n",
    "as an array of arrays of numbers with `minimum: 0`.  While NMF also\n",
    "accepts a second argument `y`, it does not use that argument.\n",
    "Therefore, Lale gives `y` the empty schema `{}`, which permits any\n",
    "values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "{\n",
       "    'type': 'object',\n",
       "    'required': ['X'],\n",
       "    'additionalProperties': false,\n",
       "    'properties': {\n",
       "        'X': {\n",
       "            'type': 'array',\n",
       "            'items': {\n",
       "                'type': 'array',\n",
       "                'items': {\n",
       "                    'type': 'number',\n",
       "                    'minimum': 0.0}}},\n",
       "        'y': {}}}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "lale.helpers.wrap_imported_operators()\n",
    "ipython_display(NMF.input_schema_fit())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Customizing Schemas from a Notebook\n",
    "\n",
    "While you can use Lale schemas as-is, you can also customize the\n",
    "schemas to excert more control over the automation. As one example,\n",
    "recall that in an earlier example in this notebook XGBoost was tuned\n",
    "to use a large number for `n_estimators`. Hence, you might want to\n",
    "reduce the number of trees in an XGBoost forest to reduce memory\n",
    "consumption or to improve explainability. As another example, you\n",
    "might want to hand-pick one of the boosters to reduce the search space\n",
    "and thus hopefully speed up the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lale.schemas as schemas\n",
    "Grove = XGBoost.customize_schema(\n",
    "    n_estimators=schemas.Int(min=2, max=6),\n",
    "    booster=schemas.Enum(['gbtree']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this example demonstrates, Lale provides a simple Python API for\n",
    "writing schemas, which it then converts to JSON Schema internally. The\n",
    "result of customization is a new copy of the operator that can be used\n",
    "in the same way as any other operator in Lale. In particular, it can\n",
    "be part of a pipeline as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"254pt\" height=\"102pt\"\n",
       " viewBox=\"0.00 0.00 254.47 101.80\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 97.799)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-97.799 250.468,-97.799 250.468,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<g id=\"a_node1\"><a xlink:href=\"https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\" xlink:title=\"PCA\">\n",
       "<ellipse fill=\"#7ec0ee\" stroke=\"black\" cx=\"27\" cy=\"-75.799\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-72.999\" font-family=\"Times,serif\" font-size=\"11.00\">PCA</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\n",
       "<g id=\"a_node3\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.lale.concat_features.html\" xlink:title=\"ConcatFeatures\">\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"123.234\" cy=\"-47.799\" rx=\"33.4697\" ry=\"19.6\"/>\n",
       "<text text-anchor=\"middle\" x=\"123.234\" y=\"-50.999\" font-family=\"Times,serif\" font-size=\"11.00\">Concat&#45;</text>\n",
       "<text text-anchor=\"middle\" x=\"123.234\" y=\"-38.999\" font-family=\"Times,serif\" font-size=\"11.00\">Features</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M52.2676,-68.5883C61.6899,-65.7886 72.7207,-62.511 83.2014,-59.3969\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"84.4219,-62.6855 93.0108,-56.4822 82.4281,-55.9754 84.4219,-62.6855\"/>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\n",
       "<g id=\"a_node2\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.lale.no_op.html\" xlink:title=\"NoOp\">\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"27\" cy=\"-19.799\" rx=\"27\" ry=\"19.6\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-22.999\" font-family=\"Times,serif\" font-size=\"11.00\">No&#45;</text>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-10.999\" font-family=\"Times,serif\" font-size=\"11.00\">Op</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M52.2676,-27.0097C61.6899,-29.8093 72.7207,-33.087 83.2014,-36.2011\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"82.4281,-39.6225 93.0108,-39.1158 84.4219,-32.9125 82.4281,-39.6225\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\n",
       "<g id=\"a_node4\"><a xlink:href=\"https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn\" xlink:title=\"XGBoost\">\n",
       "<ellipse fill=\"#7ec0ee\" stroke=\"black\" cx=\"219.468\" cy=\"-47.799\" rx=\"27\" ry=\"19.6\"/>\n",
       "<text text-anchor=\"middle\" x=\"219.468\" y=\"-50.999\" font-family=\"Times,serif\" font-size=\"11.00\">XG&#45;</text>\n",
       "<text text-anchor=\"middle\" x=\"219.468\" y=\"-38.999\" font-family=\"Times,serif\" font-size=\"11.00\">Boost</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M156.664,-47.799C164.825,-47.799 173.638,-47.799 181.983,-47.799\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"182.217,-51.2991 192.217,-47.799 182.217,-44.2991 182.217,-51.2991\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f1403dac438>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grove_planned = lale.operators.make_pipeline(\n",
    "    lale.operators.make_union(PCA, NoOp),\n",
    "    Grove)\n",
    "lale.helpers.to_graphviz(grove_planned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this new planned pipeline, we use hyperopt as before to search\n",
    "for a good trained pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:15<00:00,  1.57s/it, best loss: 0.27217698359960163]\n",
      "CPU times: user 23.4 s, sys: 11.7 s, total: 35 s\n",
      "Wall time: 16.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grove_optimizer = HyperoptRegressor(estimator=grove_planned, cv=3, max_evals=10)\n",
    "grove_trained = grove_optimizer.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with all trained Lale pipelines, we can evaluate `grove_trained`\n",
    "with metrics to see how well it does. Also, we can pretty-print\n",
    "it back as Python code to double-check whether hyperopt obeyed the\n",
    "customized schemas for `n_estimators` and `booster`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score 0.76\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "pca = PCA(n_components=0.5129879494910545, svd_solver='full', whiten=True)\n",
       "xgboost = XGBoost(booster='gbtree', colsample_bylevel=0.41777546097517426, colsample_bytree=0.6852556915729863, learning_rate=0.4299362917360751, max_depth=15, min_child_weight=18, n_estimators=5, reg_alpha=0.052662023760107216, reg_lambda=0.04380291870028941, subsample=0.8015579071911012)\n",
       "pipeline = (pca & NoOp) >> ConcatFeatures >> xgboost\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted = grove_trained.predict(test_X)\n",
    "print(f'R2 score {sklearn.metrics.r2_score(test_y, predicted):.2f}')\n",
    "ipython_display(best_estimator(grove_trained), show_imports=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Type-Checking with Lale\n",
    "\n",
    "The rest of this notebook gives examples for how the same schemas\n",
    "that serve for auto-ML can also serve for error checking. We will\n",
    "give comparative examples for error checking in scikit-learn (without\n",
    "schemas) and in Lale (with schemas).  To make it clear which version\n",
    "of an operator is being used, all of the following examples uses\n",
    "fully-qualified names (e.g., `sklearn.feature_selection.RFE`). The\n",
    "fully-qualified names are for presentation purposes only; in typical\n",
    "usage of either scikit-learn or Lale, these would be simple names\n",
    "(e.g. just `RFE`).\n",
    "\n",
    "### 3.1 Hyperparameter Error Example in Scikit-Learn\n",
    "\n",
    "First, we import a few things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import sklearn\n",
    "from sklearn import pipeline, feature_selection, ensemble, tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `make_pipeline` to compose a pipeline of two steps: an RFE\n",
    "transformer and a decision tree regressor. RFE performs recursive\n",
    "feature elimination, keeping only those features of the input data\n",
    "that are the most useful for its `estimator` argument. For RFE's\n",
    "estimator argument, the following code uses a random forest with 10\n",
    "trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_hyperparam_error = sklearn.pipeline.make_pipeline(\n",
    "    sklearn.feature_selection.RFE(\n",
    "        estimator=sklearn.ensemble.RandomForestRegressor(n_estimators=10)),\n",
    "    sklearn.tree.DecisionTreeRegressor(max_depth=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `max_depth` argument for a decision tree cannot be a\n",
    "negative number. Hence, the above code actually contains a bug: it\n",
    "sets `max_depth=-1`. Scikit-learn does not check for this mistake from\n",
    "the `__init__` method, otherwise we would have seen an error message\n",
    "already. Instead, scikit-learn checks for this mistake during `fit`.\n",
    "Unfortunately, it takes a few seconds to get the exception, because\n",
    "scikit-learn first trains the RFE transformer and uses it to transform\n",
    "the data. Only then does it pass the data to the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.48 s, sys: 172 ms, total: 7.66 s\n",
      "Wall time: 7.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_depth must be greater than zero. \n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "try:\n",
    "    sklearn_hyperparam_error.fit(train_X, train_y)\n",
    "except ValueError as e:\n",
    "    message = str(e)\n",
    "print(message, file=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, this error message is pretty clear. Scikit-learn\n",
    "implements the error check imperatively, using Python if-statements\n",
    "to raise an exception when hyperparameters are configured wrong.\n",
    "This notebook is part of Lale's regression test suite and gets run\n",
    "automatically when changes are pushed to the Lale source code\n",
    "repository. The assertion in the following cell is a test that the\n",
    "error-check indeed behaves as expected and documented here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert message.startswith(\"max_depth must be greater than zero.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Checking Hyperparameters with Types\n",
    "\n",
    "Lale performs the same error checks, but using JSON Schema validation\n",
    "instead of Python if-statements and raise-statements. First, we import\n",
    "the `jsonschema` validator so we can catch its exceptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonschema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the exact same pipeline as before, but written in Lale\n",
    "instead of directly in scikit-learn. In both cases, the underlying\n",
    "implementation is in scikit-learn; Lale only adds thin wrappers to\n",
    "support type checking and auto-ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.9 ms, sys: 0 ns, total: 46.9 ms\n",
      "Wall time: 46.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid configuration for DecisionTreeRegressor(max_depth=-1) due to invalid value max_depth=-1.\n",
      "Schema of argument max_depth: {\n",
      "    'description': 'Maximum depth of the tree.',\n",
      "    'default': null,\n",
      "    'anyOf': [\n",
      "    {   'type': 'integer',\n",
      "        'minimum': 1,\n",
      "        'minimumForOptimizer': 3,\n",
      "        'maximumForOptimizer': 5},\n",
      "    {   'enum': [null],\n",
      "        'description': 'If None, then nodes are expanded until all leaves are pure, or until all leaves contain less than min_samples_split samples.'}]}\n",
      "Value: -1\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "try:\n",
    "    lale_hyperparam_error = lale.operators.make_pipeline(\n",
    "        lale.lib.sklearn.RFE(\n",
    "            estimator=lale.lib.sklearn.RandomForestRegressor(n_estimators=10)),\n",
    "        lale.lib.sklearn.DecisionTreeRegressor(max_depth=-1))\n",
    "except jsonschema.ValidationError as e:\n",
    "    message = e.message\n",
    "print(message, file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert message.startswith(\"Invalid configuration for DecisionTreeRegressor(max_depth=-1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like in the scikit-learn example, the error message in the Lale\n",
    "example also pin-points the problem as passing `max_depth=-1` to the\n",
    "decision tree. It does so in a more stylized way, printing the\n",
    "relevant JSON schema for this hyperparameter.  Lale detects the error\n",
    "already when the wrong hyperparameter is being passed as an argument,\n",
    "thus reducing the amount of code you have to look at to find the root\n",
    "cause.  Furthermore, Lale takes only tens of milliseconds to detect\n",
    "the error, because it does not attempt to train the RFE transformer\n",
    "first. In this example, that only saves a few seconds, which may not\n",
    "be significant. But there are situations with larger time savings,\n",
    "such as when using larger datasets, slower operators, or when auto-ML\n",
    "tries out many pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Dataset Error Example in Scikit-Learn\n",
    "\n",
    "Above, we saw an example for detecting a hyperparameter error in\n",
    "scikit-learn and in Lale. Next, we look at an analogous example for a\n",
    "dataset error. Again, let's first look at the experience with\n",
    "scikit-learn and then the same thing with Lale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use scikit-learn to compose a pipeline of two steps: an RFE\n",
    "transformer as before, this time followed by an NMF transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_dataset_error = sklearn.pipeline.make_pipeline(\n",
    "    sklearn.feature_selection.RFE(\n",
    "        estimator=sklearn.ensemble.RandomForestRegressor(n_estimators=10)),\n",
    "    sklearn.decomposition.NMF())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NMF, or non-negative matrix factorization, does not allow any negative\n",
    "numbers in its input matrix. The California Housing dataset contains\n",
    "some negative numbers and the RFE does not eliminate those features.\n",
    "To detect the mistake, scikit-learn must first train the RFE and\n",
    "transform the data with it, which takes a few seconds. Then, NMF\n",
    "detects the error and throws an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.8 s, sys: 46.9 ms, total: 7.84 s\n",
      "Wall time: 7.95 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Negative values in data passed to NMF (input X)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "try:\n",
    "    sklearn_dataset_error.fit(train_X, train_y)\n",
    "except ValueError as e:\n",
    "    message = str(e)\n",
    "print(message, file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert message.startswith(\"Negative values in data passed to NMF (input X)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Types for Dataset Checking\n",
    "\n",
    "Lale uses types (as expressed using JSON schemas) to check\n",
    "dataset-related mistakes. Below is the same pipeline as before, using\n",
    "thin Lale wrappers around scikit-learn operators. We redefine the\n",
    "pipeline to enable Lale type-checking for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lale_dataset_error = lale.operators.make_pipeline(\n",
    "    lale.lib.sklearn.RFE(\n",
    "        estimator=lale.lib.sklearn.RandomForestRegressor(n_estimators=10)),\n",
    "    lale.lib.sklearn.NMF())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of calling `fit` on the pipeline, we call `validate_schema`.\n",
    "This does not perform training, but rather, just checks that the\n",
    "schema is correct at each step of the pipeline. In other words, it\n",
    "checks whether the schema of the input data is valid for the first\n",
    "step of the pipeline, and that the schema of the output from each step\n",
    "is valid for the next step. By saving the time for training the RFE,\n",
    "this completes in tens of milliseconds instead of seconds as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 109 ms, sys: 15.6 ms, total: 125 ms\n",
      "Wall time: 102 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NMF.fit() invalid X: Expected sub to be a subschema of super.\n",
      "sub = {\n",
      "    'type': 'array',\n",
      "    'items': {\n",
      "        'type': 'array',\n",
      "        'items': {\n",
      "            'type': 'number'}}}\n",
      "super = {\n",
      "    'type': 'array',\n",
      "    'items': {\n",
      "        'type': 'array',\n",
      "        'items': {\n",
      "            'type': 'number',\n",
      "            'minimum': 0.0}}}\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "try:\n",
    "    lale_dataset_error.validate_schema(train_X, train_y)\n",
    "except ValueError as e:\n",
    "    message = str(e)\n",
    "print(message, file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert message.startswith('NMF.fit() invalid X: Expected sub to be a subschema of super.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the schemas for `X` differ: whereas the data is an\n",
    "array of arrays of unconstrained numbers, NMF expects an array of\n",
    "arrays of only non-negative numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Hyperparameter Constraint Example in Scikit-Learn\n",
    "\n",
    "Sometimes, the validity of hyperparameters cannot be checked in\n",
    "isolation. Instead, the value of one hyperparameter can restrict\n",
    "which values are valid for another hyperparameter. For example,\n",
    "scikit-learn imposes a conditional hyperparameter constraint between\n",
    "the `svd_solver` and `n_components` arguments to PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_constraint_error = sklearn.pipeline.make_pipeline(\n",
    "    sklearn.feature_selection.RFE(\n",
    "        estimator=sklearn.ensemble.RandomForestRegressor(n_estimators=10)),\n",
    "    sklearn.decomposition.PCA(svd_solver='arpack', n_components='mle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above notebook cell completed successfully, because scikit-learn\n",
    "did not yet check for the constraint. To observe the error message\n",
    "with scikit-learn, we must attempt to fit the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.86 s, sys: 46.9 ms, total: 7.91 s\n",
      "Wall time: 8.07 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "n_components='mle' cannot be a string with svd_solver='arpack'\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "message=None\n",
    "try:\n",
    "    sklearn_constraint_error.fit(train_X, train_y)\n",
    "except ValueError as e:\n",
    "    message = str(e)\n",
    "print(message, file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert message.startswith(\"n_components='mle' cannot be a string with svd_solver='arpack'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn implements constraint-checking as Python code with\n",
    "if-statements and raise-statements. After a few seconds, we get an\n",
    "exception, and the error message explains what went wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Types for Constraint Checking\n",
    "\n",
    "Lale specifies constraints using JSON Schemas. When you configure an\n",
    "operator with actual hyperparameters, Lale immediately validates them\n",
    "against their schema including constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.2 ms, sys: 15.6 ms, total: 46.9 ms\n",
      "Wall time: 52.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid configuration for PCA(svd_solver='arpack', n_components='mle') due to constraint option n_components mle can only be set for svd_solver full or auto.\n",
      "Schema of constraint 1: {\n",
      "    'description': 'Option n_components mle can only be set for svd_solver full or auto.',\n",
      "    'anyOf': [\n",
      "    {   'type': 'object',\n",
      "        'properties': {\n",
      "            'n_components': {\n",
      "                'not': {\n",
      "                    'enum': ['mle']}}}},\n",
      "    {   'type': 'object',\n",
      "        'properties': {\n",
      "            'svd_solver': {\n",
      "                'enum': ['full', 'auto']}}}]}\n",
      "Value: {'svd_solver': 'arpack', 'n_components': 'mle', 'copy': True, 'whiten': False, 'tol': 0.0, 'iterated_power': 'auto', 'random_state': None}\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "try:\n",
    "    lale_constraint_error = lale.operators.make_pipeline(\n",
    "        lale.lib.sklearn.RFE(\n",
    "            estimator=lale.lib.sklearn.RandomForestRegressor(n_estimators=10)),\n",
    "        PCA(svd_solver='arpack', n_components='mle'))\n",
    "except jsonschema.ValidationError as e:\n",
    "    message = str(e)\n",
    "print(message, file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert message.startswith(\"Invalid configuration for PCA(svd_solver='arpack', n_components='mle')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lale reports the error quicker than scikit-learn, taking only tens of\n",
    "milliseconds instead of multiple seconds. The error message contains\n",
    "both a natural-language description of the constraint and its formal\n",
    "representation in JSON Schema. The `'anyOf'` implements an 'or', so\n",
    "you can read the constraints as\n",
    "\n",
    "```python\n",
    "(not (n_components in ['mle'])) or (svd_solver in ['full', 'auto'])\n",
    "```\n",
    "\n",
    "By basic Boolean algebra, this is equivalent to an implication\n",
    "\n",
    "```python\n",
    "(n_components in ['mle']) implies (svd_solver in ['full', 'auto'])\n",
    "```\n",
    "\n",
    "Since the constraint is specified declaratively in the schema, it gets\n",
    "applied wherever the schema gets used. Specifically, the constraint\n",
    "gets applied both during auto-ML and during type-checking. In the\n",
    "context of auto-ML, the constraint prunes the search space: it\n",
    "eliminates some hyperparameter combinations so that the auto-ML tool\n",
    "does not have to try them out. We have observed cases where this\n",
    "pruning makes a big difference in search convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusion\n",
    "\n",
    "This notebook showed additions to scikit-learn that simplify auto-ML\n",
    "as well as error checking. The common foundation for both of these\n",
    "additions is schemas for operators. For further reading, return to the\n",
    "Lale github [repository](https://github.com/ibm/lale), where you can\n",
    "find installation instructions, an FAQ, and links to further\n",
    "documentation, notebooks, talks, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
